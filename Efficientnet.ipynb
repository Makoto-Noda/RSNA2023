{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # to avoid too many logging messages\n",
    "import pandas as pd, numpy as np, random, shutil\n",
    "import tensorflow as tf, re, math\n",
    "import tensorflow.keras.backend as K\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "#from IPython import display as ipd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"RSNA2023ATDEfficientnet\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb         = True\n",
    "\n",
    "    '''\n",
    "    competition   = 'RSNA2023ATD' \n",
    "    _wandb_kernel = 'm-noda'\n",
    "    debug         = False\n",
    "    comment       = 'EfficientNetV1B1-512x512-lr2-vflip'\n",
    "    exp_name      = 'baseline-v5: ds-v3 + multi_head' \n",
    "    '''\n",
    "    \n",
    "    # use verbose=0 for silent, vebose=1 for interactive,\n",
    "    verbose      = 0\n",
    "    display_plot = True\n",
    "\n",
    "    # device\n",
    "    #device = \"TPU-VM\" #or \"GPU\"\n",
    "\n",
    "    model_name = 'EfficientNet'\n",
    "\n",
    "    seed = 123\n",
    "\n",
    "    folds = 5\n",
    "    \n",
    "    # which folds to train\n",
    "    selected_folds = [0, 1]\n",
    "\n",
    "    # size of the image\n",
    "    img_size = [512, 512]\n",
    "\n",
    "    batch_size = 8\n",
    "    epochs = 12\n",
    "\n",
    "    loss      = 'BCE & CCE'\n",
    "    \n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    augment   = True\n",
    "\n",
    "    # scale-shift-rotate-shear\n",
    "    transform = 0.90  # transform prob\n",
    "    fill_mode = 'constant'\n",
    "    rot    = 2.0\n",
    "    shr    = 2.0\n",
    "    hzoom  = 50.0\n",
    "    wzoom  = 50.0\n",
    "    hshift = 10.0\n",
    "    wshift = 10.0\n",
    "\n",
    "    # flip\n",
    "    hflip = True\n",
    "    vflip = True\n",
    "\n",
    "    # clip\n",
    "    clip = False\n",
    "\n",
    "    # lr-scheduler\n",
    "    scheduler   = 'exp' # cosine\n",
    "\n",
    "    '''\n",
    "    # dropout\n",
    "    drop_prob   = 0.6\n",
    "    drop_cnt    = 5\n",
    "    drop_size   = 0.05\n",
    "    \n",
    "    # cut-mix-up\n",
    "    mixup_prob = 0.0\n",
    "    mixup_alpha = 0.5\n",
    "    cutmix_prob = 0.0\n",
    "    cutmix_alpha = 2.5\n",
    "    '''\n",
    "\n",
    "    # pixel-augment\n",
    "    #pixel_aug = 0.90  # prob of pixel_aug\n",
    "    sat  = [0.7, 1.3]\n",
    "    cont = [0.8, 1.2]\n",
    "    bri  = 0.15\n",
    "    hue  = 0.05\n",
    "\n",
    "    # test-time augs\n",
    "    tta = 1\n",
    "    \n",
    "    # target column\n",
    "    target_col  = [ \"bowel_injury\", \"extravasation_injury\", \"kidney_healthy\", \"kidney_low\",\n",
    "                   \"kidney_high\", \"liver_healthy\", \"liver_low\", \"liver_high\",\n",
    "                   \"spleen_healthy\", \"spleen_low\", \"spleen_high\"] # not using \"bowel_healthy\" & \"extravasation_healthy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding done!!!\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    print('seeding done!!!')\n",
    "seeding(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make dataframes\n",
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "train_paths = glob('./train_png/*_*_*.png')\n",
    "train_df['image_path'] = f'./train_png/' + \\\n",
    "                            train_df.patient_id.astype(str) + '_' + \\\n",
    "                            train_df.series_id.astype(str) + '_' + \\\n",
    "                            train_df.img_number.astype(str).str.zfill(3) + '.png'\n",
    "\n",
    "test_paths = glob('./test_png/*_*_*.png')\n",
    "test_df = pd.DataFrame(test_paths, columns=[\"image_path\"])\n",
    "test_df['patient_id'] = test_df.image_path.map(lambda x: x.split('_')[-3].replace('png/','')).astype(int)\n",
    "test_df['series_id'] = test_df.image_path.map(lambda x: x.split('_')[-2]).astype(int)\n",
    "test_df['img_number'] = test_df.image_path.map(lambda x: x.split('_')[-1].replace('.png','')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.gfile.exists(train_df.image_path.iloc[0]), tf.io.gfile.exists(test_df.image_path.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split into train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  patient_id\n",
       "0.0   96            130\n",
       "      318           134\n",
       "      384           110\n",
       "      470           103\n",
       "      496           133\n",
       "                   ... \n",
       "4.0   65289         147\n",
       "      65326         130\n",
       "      65438         251\n",
       "      65450         132\n",
       "      65495         149\n",
       "Length: 3147, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['stratify'] = ''\n",
    "\n",
    "for col in CFG.target_col:\n",
    "    train_df['stratify'] += train_df[col].astype(str)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for  fold , (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['stratify'], train_df['patient_id'])):\n",
    "    train_df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "display(train_df.groupby(['fold', 'patient_id']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int(shape=[], minval=0, maxval=1):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n",
    "\n",
    "\n",
    "def random_float(shape=[], minval=0.0, maxval=1.0):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# make affine transformation matrix\n",
    "def get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift)\n",
    "    \n",
    "    # degrees to radians\n",
    "    shear = math.pi * shear / 180\n",
    "\n",
    "\n",
    "    def get_3x3_mat(list):\n",
    "        return tf.reshape(tf.concat([list], axis=0), [3, 3])\n",
    "    \n",
    "\n",
    "    one = tf.constant([1], dtype='float32')\n",
    "    zero = tf.constant([0], dtype='float32')\n",
    "\n",
    "\n",
    "    # for shear matrix\n",
    "    cos = tf.math.cos(shear)\n",
    "    sin = tf.math.sin(shear)\n",
    "\n",
    "    shear_matrix = get_3x3_mat([one,  sin,  zero,\n",
    "                                zero, cos,  zero,\n",
    "                                zero, zero, one])\n",
    "    \n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero,\n",
    "                               zero,            one/width_zoom, zero,\n",
    "                               zero,            zero,           one])\n",
    "    \n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    #ã€€return composite transformation\n",
    "    return K.dot(shear_matrix, k.dot(zoom_matrix, shift_matrix))\n",
    "    \n",
    "\n",
    "# apply affine transformation\n",
    "def transform(image, DIM=CFG.img_size):\n",
    "\n",
    "    # add padding to align image sizes\n",
    "    if DIM[0]>DIM[1]:\n",
    "        diff  = (DIM[0]-DIM[1])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[0, 0], [pad[0], pad[1]],[0, 0]])\n",
    "        NEW_DIM = DIM[0]\n",
    "\n",
    "    elif DIM[0]<DIM[1]:\n",
    "        diff  = (DIM[1]-DIM[0])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[pad[0], pad[1]], [0, 0],[0, 0]])\n",
    "        NEW_DIM = DIM[1]\n",
    "\n",
    "    rotation     = CFG.rot * tf.random.normal([1], dtype='float32')\n",
    "    rotation     = math.pi * rotation / 180.\n",
    "    shear        = CFG.shr * tf.random.normal([1], dtype='float32') \n",
    "    height_zoom  = 1.0 + tf.random.normal([1], dtype='float32') / CFG.hzoom\n",
    "    width_zoom   = 1.0 + tf.random.normal([1], dtype='float32') / CFG.wzoom\n",
    "    height_shift = CFG.hshift * tf.random.normal([1], dtype='float32') \n",
    "    width_shift  = CFG.wshift * tf.random.normal([1], dtype='float32')\n",
    "\n",
    "    # inverse of get_matrix\n",
    "    # https://daeudaeu.com/reverse-matorix/\n",
    "    transformation_matrix     =tf.linalg.inv(get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift))\n",
    "    transformation_matrix_flat=tfa.image.transform_ops.matrices_to_flat_transforms(transformation_matrix)\n",
    "\n",
    "    # apply affine transformation to image\n",
    "    image=tfa.image.transform(image,flat_tensor, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # rotate image\n",
    "    image=tfa.image.rotate(image,-rotation, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # remove padding\n",
    "    if DIM[0]>DIM[1]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,4])\n",
    "        image = image[:, pad[0]:-pad[1],:]\n",
    "    elif DIM[1]>DIM[0]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,4])\n",
    "        image = image[pad[0]:-pad[1],:,:]\n",
    "\n",
    "    # align image sizes\n",
    "    image = tf.reshape(image, [*DIM, 4])  \n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# apply dropout to image\n",
    "def dropout(image,DIM=CFG.img_size, PROBABILITY = 0.6, cutout = 5, size = 0.1):\n",
    "\n",
    "    # boolean to int\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "\n",
    "    if (P==0) or (cutout==0) or (size==0):\n",
    "        return image\n",
    "    \n",
    "    for c in range(cutout):\n",
    "\n",
    "        # choose random coordinates\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM[1]),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM[0]),tf.int32)\n",
    "\n",
    "        # determine cutout square\n",
    "        width = tf.cast(size*min(DIM),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-width//2)\n",
    "        yb = tf.math.minimum(DIM[0],y+width//2)\n",
    "        xa = tf.math.maximum(0,x-width//2)\n",
    "        xb = tf.math.minimum(DIM[1],x+width//2)\n",
    "\n",
    "        # image after cutout\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,4], dtype = image.dtype) # cutouted square\n",
    "        three = image[ya:yb,xb:DIM[1],:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM[0],:,:]],axis=0)\n",
    "        image = tf.reshape(image,[*DIM,4])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# apply color augmentation\n",
    "def ColorAug(image, PROBABILITY):\n",
    "\n",
    "    if random_float() > prob:\n",
    "        return image\n",
    "    \n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    # separate alpha channel\n",
    "    image_rgb, image_alpha = image[:, :, :3], img[:, :, 3:]\n",
    "\n",
    "    # apply random color adjustment to the RGB channels\n",
    "    image_rgb = tf.image.random_hue(image_rgb, CFG.hue)\n",
    "    image_rgb = tf.image.random_saturation(image_rgb, CFG.sat[0], CFG.sat[1])\n",
    "    image_rgb = tf.image.random_contrast(image_rgb, CFG.cont[0], CFG.cont[1])\n",
    "    image_rgb = tf.image.random_brightness(image_rgb, CFG.bri)\n",
    "\n",
    "    # combine the adjusted RGB channels with the original alpha channel\n",
    "    image = tf.concat([image_rgb, image_alpha], axis=-1)\n",
    "\n",
    "    image = tf.reshape(image, shape)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipline\n",
    "1. Reads the PNG file and then decode it to tf.tensor\n",
    "2. Resizes the image\n",
    "3. Changes the datatype to float32\n",
    "4. Cache the data for boosting up the speed\n",
    "5. Apply augmentations \n",
    "6. Split the data into baches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decorder(with_labels=True, target_size=CFG.img_size, ext='png'):\n",
    "\n",
    "\n",
    "    def decode_image(path):\n",
    "        \n",
    "        file_binary = tf.io.read_file(path)\n",
    "\n",
    "        if ext == 'png':\n",
    "            image = tf.image.decode_png(file_binary, channels=4, dtype=tf.uint8)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsna2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
