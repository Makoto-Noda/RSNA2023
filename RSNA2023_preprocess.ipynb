{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pydicom\n",
    "from ydata_profiling import ProfileReport\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pandasの表示を設定\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:, 4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    resize_dimension = 224\n",
    "\n",
    "    seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding done!!!\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    print('seeding done!!!')\n",
    "\n",
    "seeding(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4711it [06:06, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./rsna2023atd_files/train.csv')\n",
    "series_meta_df = pd.read_csv('./rsna2023atd_files/train_series_meta.csv')\n",
    "df = df.merge(series_meta_df, on=['patient_id'], how='right')\n",
    "\n",
    "patient_series_df = pd.DataFrame(columns=['patient_id', 'series_id'])\n",
    "patient_series_df['patient_id'] = df['patient_id']\n",
    "patient_series_df['series_id'] = df['series_id']\n",
    "\n",
    "instance_df = pd.DataFrame(columns=['patient_id', 'series_id', 'instance_number', 'image_path'])\n",
    "\n",
    "\n",
    "def apply_instance_number(row):\n",
    "    \n",
    "    row['instance_number'] = (row['image_path'].split('/')[-1]).split('.')[0]\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "for pid, sid in tqdm(zip(patient_series_df['patient_id'], patient_series_df['series_id'])):\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=['patient_id', 'series_id', 'image_path'])\n",
    "\n",
    "    image_paths = glob(f'./rsna2023atd_files/train_images/{pid}/{sid}/*.dcm')\n",
    "\n",
    "    new_df['image_path'] = image_paths\n",
    "    new_df['patient_id'] = pid\n",
    "    new_df['series_id'] = sid\n",
    "    \n",
    "    new_df = new_df.apply(apply_instance_number, axis=1)\n",
    "\n",
    "    instance_df = pd.concat([instance_df, new_df])\n",
    "\n",
    "\n",
    "df = df.merge(instance_df, on=['patient_id', 'series_id'], how='right')\n",
    "df = df.sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)\n",
    "\n",
    "df.loc[df['kidney_healthy'] == 1, 'kidney_injury'] = 0\n",
    "df.loc[df['kidney_healthy'] == 0, 'kidney_injury'] = 1\n",
    "df.loc[df['liver_healthy'] == 1, 'liver_injury'] = 0\n",
    "df.loc[df['liver_healthy'] == 0, 'liver_injury'] = 1\n",
    "df.loc[df['spleen_healthy'] == 1, 'spleen_injury'] = 0\n",
    "df.loc[df['spleen_healthy'] == 0, 'spleen_injury'] = 1\n",
    "\n",
    "df['kidney_injury'] = df['kidney_injury'].astype('int')\n",
    "df['liver_injury'] = df['liver_injury'].astype('int')\n",
    "df['spleen_injury'] = df['spleen_injury'].astype('int')\n",
    "\n",
    "df = df.drop(['kidney_low', 'kidney_high', 'liver_low', 'liver_high', 'spleen_low', 'spleen_high'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pre = df[df['any_injury'] == 1]\n",
    "# train_pre_0 = df[df['any_injury'] == 0]\n",
    "\n",
    "# train_pre_1_id, test_id = train_test_split(test_pre['patient_id'], test_size=30, shuffle=True, stratify=test_pre[['bowel_injury', 'extravasation_injury', 'kidney_injury', 'liver_injury', 'spleen_injury']], random_state=123)\n",
    "# test_id_list =  test_id.to_list()\n",
    "\n",
    "# test_df = test_pre.query('patient_id in @test_id_list')\n",
    "# train_pre_1 = test_pre.query('patient_id not in @test_id_list')\n",
    "# train_df = pd.concat([train_pre_0, train_pre_1], axis=0).sort_values('patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_patient = df.drop_duplicates(subset='patient_id')\n",
    "\n",
    "train, test = train_test_split(df_unique_patient['patient_id'], test_size=100, shuffle=True, random_state=123)\n",
    "test_list = test.tolist()\n",
    "\n",
    "train_df = df.query('patient_id not in @test_list')\n",
    "test_df = df.query('patient_id in @test_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make metadata dataframes for 5 different organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = train_df[df['any_injury'] == 1]\n",
    "df_negative = train_df[df['any_injury'] == 0]\n",
    "\n",
    "df_positive['kidney_injury'] = df_positive['kidney_injury'].astype('int')\n",
    "df_positive['liver_injury'] = df_positive['liver_injury'].astype('int')\n",
    "df_positive['spleen_injury'] = df_positive['spleen_injury'].astype('int')\n",
    "df_negative['kidney_injury'] = df_negative['kidney_injury'].astype('int')\n",
    "df_negative['liver_injury'] = df_negative['liver_injury'].astype('int')\n",
    "df_negative['spleen_injury'] = df_negative['spleen_injury'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bowel_positive = df_positive[df_positive['bowel_injury'] == 1]\n",
    "df_extra_positive = df_positive[df_positive['extravasation_injury'] == 1]\n",
    "df_kidney_positive = df_positive[df_positive['kidney_injury'] == 1]\n",
    "df_liver_positive = df_positive[df_positive['liver_injury'] == 1]\n",
    "df_spleen_positive = df_positive[df_positive['spleen_injury'] == 1]\n",
    "\n",
    "len_bowel = len(df_bowel_positive['patient_id'].unique())\n",
    "len_extra = len(df_extra_positive['patient_id'].unique())\n",
    "len_kidney = len(df_kidney_positive['patient_id'].unique())\n",
    "len_liver = len(df_liver_positive['patient_id'].unique())\n",
    "len_spleen = len(df_spleen_positive['patient_id'].unique())\n",
    "\n",
    "bowel_negative_list = np.random.choice(df_negative['patient_id'].unique(), len_bowel, replace=False)\n",
    "extra_negative_list = np.random.choice(df_negative['patient_id'].unique(), len_extra, replace=False)\n",
    "kidney_negative_list = np.random.choice(df_negative['patient_id'].unique(), len_kidney, replace=False)\n",
    "liver_negative_list = np.random.choice(df_negative['patient_id'].unique(), len_liver, replace=False)\n",
    "spleen_negative_list = np.random.choice(df_negative['patient_id'].unique(), len_spleen, replace=False)\n",
    "\n",
    "df_bowel_negative = df_negative[df_negative['patient_id'].isin(bowel_negative_list.tolist())]\n",
    "df_extra_negative =  df_negative[df_negative['patient_id'].isin(extra_negative_list.tolist())]\n",
    "df_kidney_negative =  df_negative[df_negative['patient_id'].isin(kidney_negative_list.tolist())]\n",
    "df_liver_negative =  df_negative[df_negative['patient_id'].isin(liver_negative_list.tolist())]\n",
    "df_spleen_negative =  df_negative[df_negative['patient_id'].isin(spleen_negative_list.tolist())]\n",
    "\n",
    "df_bowel = (pd.concat([df_bowel_positive, df_bowel_negative])).sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)\n",
    "df_extra = (pd.concat([df_extra_positive, df_extra_negative])).sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)\n",
    "df_kidney = (pd.concat([df_kidney_positive, df_kidney_negative])).sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)\n",
    "df_liver = (pd.concat([df_liver_positive, df_liver_negative])).sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)\n",
    "df_spleen = (pd.concat([df_spleen_positive, df_spleen_negative])).sort_values(['patient_id', 'series_id', 'instance_number']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert .dcm image files to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n",
    "\n",
    "    pixel_array = dcm.pixel_array\n",
    "\n",
    "    if dcm.PixelRepresentation == 1:\n",
    "        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n",
    "        dtype = pixel_array.dtype \n",
    "        new_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n",
    "\n",
    "        pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n",
    "    \n",
    "    return pixel_array\n",
    "\n",
    "\n",
    "def read_xray(file_path, fix_monochrome = True):\n",
    "\n",
    "    dicom = pydicom.dcmread(file_path)\n",
    "    data = standardize_pixel_array(dicom)\n",
    "    data = data - np.min(data)\n",
    "    data = data / (np.max(data) + 1e-5)\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = 1.0 - data\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def resize_and_save(dir, file_path):\n",
    "    image = read_xray(file_path)\n",
    "    image = cv2.resize(image, (CFG.resize_dimension, CFG.resize_dimension), cv2.INTER_LINEAR) # bilinear interpolation\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    sub_path = file_path.split('/')[-3] + '/' + file_path.split('/')[-2] + '/' + file_path.split('/')[-1].split('.')[0] + '.png'\n",
    "\n",
    "    infos = sub_path.split('/')\n",
    "    patient_id = infos[0]\n",
    "    series_id = infos[1]\n",
    "    instance_id = infos[2]\n",
    "    instance_id = instance_id.replace('.png', '')\n",
    "\n",
    "    new_path = os.path.join(dir, sub_path)\n",
    "    os.makedirs(new_path.rsplit('/',1)[0], exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(new_path, image, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    return patient_id,series_id,instance_id,width,height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = './Dataset/test/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50243/50243 [03:49<00:00, 219.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 46.5 s, total: 4min 56s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = test_df.image_path.tolist()\n",
    "imagesize_test = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_test, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_test)\n",
    "\n",
    "test_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "test_meta_df[['patient_id', 'series_id', 'instance_number']] = test_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "test_df[['patient_id', 'series_id', 'instance_number']] = test_df[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "test_df = test_df.merge(test_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "test_df['image_path'] = dir_test + test_df.patient_id.astype(str)+ '/' + test_df.series_id.astype(str) + '/' + test_df.instance_number.astype(str) + '.png'\n",
    "\n",
    "test_df.to_csv(f'{dir_test}/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df = test_df.reindex(columns=['patient_id', 'bowel_healthy', 'bowel_injury', 'extravasation_healthy', 'extravasation_injury', \n",
    "                                  'kidney_healthy', 'kidney_injury', 'liver_healthy', 'liver_injury', 'spleen_healthy', 'spleen_injury'])\n",
    "ans_df = ans_df.drop_duplicates().sort_values('patient_id').reset_index(drop=True)\n",
    "\n",
    "ans_df.to_csv(f'{dir_test}/answer.csv', index='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for bowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_bowel = './Dataset/bowel/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59616/59616 [04:29<00:00, 221.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 48s, sys: 56.7 s, total: 5min 45s\n",
      "Wall time: 4min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = df_bowel.image_path.tolist()\n",
    "imagesize_bowel = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_bowel, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_bowel)\n",
    "\n",
    "bowel_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "bowel_meta_df[['patient_id', 'series_id', 'instance_number']] = bowel_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "df_bowel[['patient_id', 'series_id', 'instance_number']] = df_bowel[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "df_bowel = df_bowel.merge(bowel_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "df_bowel['image_path'] = dir_bowel + df_bowel.patient_id.astype(str)+ '/' + df_bowel.series_id.astype(str) + '/' + df_bowel.instance_number.astype(str) + '.png'\n",
    "\n",
    "df_bowel.to_csv(f'{dir_bowel}bowel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for extravasation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_extra = './Dataset/extravasation/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103487/103487 [08:38<00:00, 199.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 5s, sys: 3min 20s, total: 14min 25s\n",
      "Wall time: 8min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = df_extra.image_path.tolist()\n",
    "imagesize_extra = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_extra, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_extra)\n",
    "\n",
    "extra_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "extra_meta_df[['patient_id', 'series_id', 'instance_number']] = extra_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "df_extra[['patient_id', 'series_id', 'instance_number']] = df_extra[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "df_extra = df_extra.merge(extra_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "df_extra['image_path'] = dir_extra + df_extra.patient_id.astype(str)+ '/' + df_extra.series_id.astype(str) + '/' + df_extra.instance_number.astype(str) + '.png'\n",
    "\n",
    "df_extra.to_csv(f'{dir_extra}extravasation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_kidney = './Dataset/kidney/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177609/177609 [13:34<00:00, 218.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 33s, sys: 2min 45s, total: 17min 18s\n",
      "Wall time: 13min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = df_kidney.image_path.tolist()\n",
    "imagesize_kidney = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_kidney, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_kidney)\n",
    "\n",
    "kidney_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "kidney_meta_df[['patient_id', 'series_id', 'instance_number']] = kidney_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "df_kidney[['patient_id', 'series_id', 'instance_number']] = df_kidney[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "df_kidney = df_kidney.merge(kidney_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "df_kidney['image_path'] = dir_kidney + df_kidney.patient_id.astype(str)+ '/' + df_kidney.series_id.astype(str) + '/' + df_kidney.instance_number.astype(str) + '.png'\n",
    "\n",
    "df_kidney.to_csv(f'{dir_kidney}kidney.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liver_unique_patient = df_liver.drop_duplicates(subset='patient_id')\n",
    "\n",
    "df_liver_patient, df_liver_left_patient = train_test_split(df_liver_unique_patient['patient_id'], stratify=df_liver_unique_patient[['liver_healthy', 'liver_injury']], train_size=400, shuffle=True, random_state=123)\n",
    "df_liver_patient_list = df_liver_patient.tolist()\n",
    "df_liver = df_liver[df_liver['patient_id'].isin(df_liver_patient_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_liver = './Dataset/liver/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199206/199206 [13:53<00:00, 239.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 38s, sys: 2min 23s, total: 18min 2s\n",
      "Wall time: 13min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = df_liver.image_path.tolist()\n",
    "imagesize_liver = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_liver, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_liver)\n",
    "\n",
    "liver_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "liver_meta_df[['patient_id', 'series_id', 'instance_number']] = liver_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "df_liver[['patient_id', 'series_id', 'instance_number']] = df_liver[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "df_liver = df_liver.merge(liver_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "df_liver['image_path'] = dir_liver + df_liver.patient_id.astype(str)+ '/' + df_liver.series_id.astype(str) + '/' + df_liver.instance_number.astype(str) + '.png'\n",
    "\n",
    "df_liver.to_csv(f'{dir_liver}liver.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for spleen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spleen_unique_patient = df_spleen.drop_duplicates(subset='patient_id')\n",
    "\n",
    "df_spleen_patient, df_spleen_left_patient = train_test_split(df_spleen_unique_patient['patient_id'], stratify=df_spleen_unique_patient[['spleen_healthy', 'spleen_injury']], train_size=400, shuffle=True, random_state=123)\n",
    "df_spleen_patient_list = df_spleen_patient.tolist()\n",
    "df_spleen = df_spleen[df_spleen['patient_id'].isin(df_spleen_patient_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_spleen = './Dataset/spleen/'\n",
    "\n",
    "image_size = [CFG.resize_dimension, CFG.resize_dimension]\n",
    "index = 0\n",
    "parts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/192524 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192524/192524 [35:37<00:00, 90.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 43s, sys: 4min 51s, total: 39min 35s\n",
      "Wall time: 35min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = df_spleen.image_path.tolist()\n",
    "imagesize_spleen = Parallel(n_jobs=-1,backend='threading')(delayed(resize_and_save)(dir_spleen, file_path) for file_path in tqdm(file_paths, leave=True, position=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid, sid, iid, width, height = zip(*imagesize_spleen)\n",
    "\n",
    "spleen_meta_df = pd.DataFrame({'patient_id'     : pid,\n",
    "                            'series_id'       : sid,\n",
    "                            'instance_number' : iid,\n",
    "                            'width'           : width,\n",
    "                            'height'          : height})\n",
    "\n",
    "spleen_meta_df[['patient_id', 'series_id', 'instance_number']] = spleen_meta_df[['patient_id', 'series_id', 'instance_number']].astype(int)\n",
    "df_spleen[['patient_id', 'series_id', 'instance_number']] = df_spleen[['patient_id', 'series_id', 'instance_number']].astype('int')\n",
    "\n",
    "df_spleen = df_spleen.merge(spleen_meta_df, on=['patient_id','series_id','instance_number'], how='right')\n",
    "\n",
    "df_spleen['image_path'] = dir_spleen + df_spleen.patient_id.astype(str)+ '/' + df_spleen.series_id.astype(str) + '/' + df_spleen.instance_number.astype(str) + '.png'\n",
    "\n",
    "df_spleen.to_csv(f'{dir_spleen}/spleen.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df_spleen, title=\"Profiling Report:Train\", minimal=True)\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
