{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import math\n",
    "import tensorflow.keras.backend as K\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from keras_cv_attention_models import efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    model_name = 'EfficientNetV2B0'\n",
    "\n",
    "    batch_size = 8\n",
    "    \n",
    "    epochs = 3\n",
    "\n",
    "    folds = 2\n",
    "\n",
    "    seed = 123\n",
    "\n",
    "    img_size = [512, 512]\n",
    "\n",
    "    augment   = True\n",
    "\n",
    "    transform_prob = 0.90\n",
    "    fill_mode = 'constant'\n",
    "    rot    = 2.0\n",
    "    shr    = 4.0\n",
    "    hzoom  = 50.0\n",
    "    wzoom  = 50.0\n",
    "    hshift = 30.0\n",
    "    wshift = 30.0\n",
    "\n",
    "    hflip = True\n",
    "    vflip = True\n",
    "\n",
    "    p_pixel_aug = 0.90\n",
    "    cont = [0.5, 2]\n",
    "    bri  = 0.5\n",
    "\n",
    "    clip = False\n",
    "\n",
    "    drop_prob   = 0.6\n",
    "    drop_cnt    = 10\n",
    "    drop_size   = 0.05\n",
    "\n",
    "    mixup_prob = 0.5\n",
    "    mixup_alpha = 0.2\n",
    "    \n",
    "    cutmix_prob = 0.5\n",
    "    cutmix_alpha = 2.5\n",
    "\n",
    "    target_col  = [ \"bowel_injury\", \"extravasation_injury\", \"kidney_healthy\", \"kidney_low\",\n",
    "                   \"kidney_high\", \"liver_healthy\", \"liver_low\", \"liver_high\",\n",
    "                   \"spleen_healthy\", \"spleen_low\", \"spleen_high\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding done!!!\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    print('seeding done!!!')\n",
    "\n",
    "seeding(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('./Dataset/test.csv')\n",
    "test_df['image_path'] = (f'./Dataset/test_images/'\n",
    "                          + test_df.patient_id.astype(str)+ '/' \n",
    "                          + test_df.series_id.astype(str) + '/' \n",
    "                          + test_df.instance_number.astype(str) \n",
    "                          + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asign Fold numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold  patient_id\n",
       "0.0   33             38\n",
       "      43             59\n",
       "      263            12\n",
       "      2602           17\n",
       "      3401            9\n",
       "                   ... \n",
       "1.0   58863         407\n",
       "      61468          64\n",
       "      61742         104\n",
       "      62397          54\n",
       "      63665          99\n",
       "Length: 246, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['stratify'] = ''\n",
    "\n",
    "for col in CFG.target_col:\n",
    "    df['stratify'] += df[col].astype(str)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for  fold , (train_idx, val_idx) in enumerate(sgkf.split(df, df['stratify'], df['patient_id'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "display(df.groupby(['fold', 'patient_id']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int(shape=[], minval=0, maxval=1):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "def random_float(shape=[], minval=0.0, maxval=1.0):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "# make affine transformation matrix\n",
    "# https://cs.kwansei.ac.jp/prog1/affine.html\n",
    "def get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "\n",
    "    # degrees to radians\n",
    "    shear = math.pi * shear / 180.\n",
    "\n",
    "\n",
    "    def get_3x3_mat(list):\n",
    "        return tf.reshape(tf.concat([list], axis=0), [3, 3])\n",
    "    \n",
    "\n",
    "    one = tf.constant([1], dtype='float32')\n",
    "    zero = tf.constant([0], dtype='float32')\n",
    "\n",
    "    # for shear matrix\n",
    "    cos = tf.math.cos(shear)\n",
    "    sin = tf.math.sin(shear)\n",
    "\n",
    "    shear_matrix = get_3x3_mat([one,  sin,  zero,\n",
    "                                zero, cos,  zero,\n",
    "                                zero, zero, one])\n",
    "    \n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero,\n",
    "                               zero,            one/width_zoom, zero,\n",
    "                               zero,            zero,           one])\n",
    "    \n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    #ã€€return composite transformation\n",
    "    return K.dot(shear_matrix, K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "\n",
    "# apply affine transformation\n",
    "def transform(image, DIM=CFG.img_size):\n",
    "\n",
    "    # add padding to align image sizes\n",
    "    if DIM[0]>DIM[1]:\n",
    "        diff  = (DIM[0]-DIM[1])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[0, 0], [pad[0], pad[1]],[0, 0]])\n",
    "        NEW_DIM = DIM[0]\n",
    "\n",
    "    elif DIM[0]<DIM[1]:\n",
    "        diff  = (DIM[1]-DIM[0])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[pad[0], pad[1]], [0, 0],[0, 0]])\n",
    "        NEW_DIM = DIM[1]\n",
    "    \n",
    "    rotation     = CFG.rot * tf.random.normal([1], dtype='float32')\n",
    "    shear        = CFG.shr * tf.random.normal([1], dtype='float32')\n",
    "    height_zoom  = 1.0 + tf.random.normal([1], dtype='float32') / CFG.hzoom\n",
    "    width_zoom   = 1.0 + tf.random.normal([1], dtype='float32') / CFG.wzoom\n",
    "    height_shift = CFG.hshift * tf.random.normal([1], dtype='float32') \n",
    "    width_shift  = CFG.wshift * tf.random.normal([1], dtype='float32')\n",
    "\n",
    "    # inverse of get_matrix\n",
    "    # https://daeudaeu.com/reverse-matorix/\n",
    "    transformation_matrix     =tf.linalg.inv(get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift))\n",
    "    transformation_matrix_flat=tfa.image.transform_ops.matrices_to_flat_transforms(transformation_matrix)\n",
    "\n",
    "    # apply affine transformation to image\n",
    "    image=tfa.image.transform(image, transformation_matrix_flat, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # rotate image\n",
    "    image=tfa.image.rotate(image, -rotation, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # remove padding\n",
    "    if DIM[0]>DIM[1]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,3])\n",
    "        image = image[:, pad[0]:-pad[1],:]\n",
    "    elif DIM[1]>DIM[0]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,3])\n",
    "        image = image[pad[0]:-pad[1],:,:]\n",
    "\n",
    "    # align image sizes\n",
    "    image = tf.reshape(image, [*DIM, 3])  \n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# apply dropout to image\n",
    "def dropout(image,DIM=CFG.img_size, PROBABILITY = 0.6, cutout = 5, size = 0.1):\n",
    "\n",
    "    # boolean to int\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "\n",
    "    if (P==0) or (cutout==0) or (size==0):\n",
    "        return image\n",
    "    \n",
    "    for c in range(cutout):\n",
    "\n",
    "        # choose random coordinates\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM[1]),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM[0]),tf.int32)\n",
    "\n",
    "        # determine cutout square\n",
    "        width = tf.cast(size*min(DIM),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-width//2)\n",
    "        yb = tf.math.minimum(DIM[0],y+width//2)\n",
    "        xa = tf.math.maximum(0,x-width//2)\n",
    "        xb = tf.math.minimum(DIM[1],x+width//2)\n",
    "\n",
    "        # image after cutout\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3], dtype = image.dtype) # cutouted square\n",
    "        three = image[ya:yb,xb:DIM[1],:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM[0],:,:]],axis=0)\n",
    "        image = tf.reshape(image,[*DIM,3])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# apply mixup amd cutmix to image\n",
    "# https://cvml-expertguide.net/terms/dl/regularization/data-augmentation/\n",
    "# mixup\n",
    "def get_mixup(alpha, prob):\n",
    "    \n",
    "    \n",
    "    # https://qiita.com/AseiSugiyama/items/66a75610c569a23ac493\n",
    "    @tf.function\n",
    "    def mixup(images, labels, alpha=alpha, prob=prob):\n",
    "\n",
    "        if random_float() > prob:\n",
    "            return images, labels\n",
    "        \n",
    "        image_shape = tf.shape(images)\n",
    "        label_shape = tf.shape(labels) # label shape has (20,1) and (20,3) mixed in it so can't get the shape\n",
    "\n",
    "        beta = tfp.distributions.Beta(alpha, alpha)\n",
    "        lamb = beta.sample(1)[0]\n",
    "\n",
    "        images = lamb * images + (1.0 - lamb) * tf.roll(images, shift=1, axis=0)\n",
    "        labels = lamb * labels + (1.0 - lamb) * tf.roll(labels, shift=1, axis=0)\n",
    "\n",
    "        images = tf.reshape(images, image_shape)\n",
    "        labels = tf.reshape(labels, label_shape)\n",
    "\n",
    "        return images, labels\n",
    "    \n",
    "    return mixup\n",
    "\n",
    "\n",
    "\n",
    "# cutmix\n",
    "def get_cutmix(alpha, prob):\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def cutmix(images, labels, alpha=alpha, prob=prob):\n",
    "\n",
    "        if random_float() > prob:\n",
    "            return images, labels\n",
    "        \n",
    "        image_shape = tf.shape(images)\n",
    "        label_shape = tf.shape(labels) # label shape has (20,1) and (20,3) mixed in it so can't get the shape\n",
    "\n",
    "        width = tf.cast(image_shape[2], tf.int32)\n",
    "        height = tf.cast(image_shape[1], tf.int32)\n",
    "\n",
    "        beta = tfp.distributions.Beta(alpha, alpha)\n",
    "        lamb = beta.sample(1)[0]\n",
    "\n",
    "        r_x = random_int([], minval=0, maxval=width)\n",
    "        r_y = random_int([], minval=0, maxval=height)\n",
    "        r = 0.5 * tf.math.sqrt(1.0 - lamb)\n",
    "        r_w_half = tf.cast(r * tf.cast(width, tf.float32), tf.int32)\n",
    "        r_h_half = tf.cast(r * tf.cast(height, tf.float32), tf.int32)\n",
    "\n",
    "        x1 = tf.cast(tf.clip_by_value(r_x - r_w_half, 0, width), tf.int32)\n",
    "        x2 = tf.cast(tf.clip_by_value(r_x + r_w_half, 0, width), tf.int32)\n",
    "        y1 = tf.cast(tf.clip_by_value(r_y - r_h_half, 0, height), tf.int32)\n",
    "        y2 = tf.cast(tf.clip_by_value(r_y + r_h_half, 0, height), tf.int32)\n",
    "\n",
    "        # outer-pad patch -> [0, 0, 1, 1, 0, 0]\n",
    "        patch1 = images[:, y1:y2, x1:x2, :]  # [batch, height, width, channel]\n",
    "        patch1 = tf.pad(patch1, [[0, 0], [y1, height - y2], [x1, width - x2], [0, 0]])  # outer-pad\n",
    "\n",
    "        # inner-pad patch -> [1, 1, 0, 0, 1, 1]\n",
    "        patch2 = tf.roll(images, shift=1, axis=0)[:, y1:y2, x1:x2, :]\n",
    "        patch2 = tf.pad(patch2, [[0, 0], [y1, height - y2], [x1, width - x2], [0, 0]])\n",
    "        patch2 = tf.roll(images, shift=1, axis=0) - patch2  # inner-pad = img - outer-pad\n",
    "\n",
    "        images = patch1 + patch2  # cutmix img\n",
    "\n",
    "        lambda2 = tf.cast((1.0 - (x2 - x1) * (y2 - y1) / (width * height)), tf.float32)\n",
    "        labels = lambda2 * labels + (1.0 - lambda2) * tf.roll(labels, shift=1, axis=0)\n",
    "\n",
    "        images = tf.reshape(images, image_shape)\n",
    "        labels = tf.reshape(labels, label_shape)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    return cutmix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pipeline\n",
    "1. Reads the PNG file and then decode it to tf.tensor\n",
    "2. Resizes the image\n",
    "3. Changes the datatype to float32\n",
    "4. Cache the data for boosting up the speed\n",
    "5. Apply augmentations \n",
    "6. Split the data into baches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(with_labels=True, target_size=CFG.img_size):\n",
    "\n",
    "\n",
    "    def decode_image(path):\n",
    "\n",
    "        file_binary = tf.io.read_file(path)\n",
    "        image = tf.image.decode_png(file_binary, channels=3, dtype=tf.uint8)\n",
    "        image = tf.image.resize(image, CFG.img_size, method='bilinear')\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = tf.reshape(image, [*CFG.img_size, 3])\n",
    "\n",
    "        return image\n",
    "    \n",
    "\n",
    "    def decode_label(label):\n",
    "        \n",
    "        label = tf.cast(label, tf.float32)\n",
    "        \n",
    "        return (label[0:1], label[1:2], label[2:5], label[5:8], label[8:11])\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "\n",
    "        return decode_image(path), decode_label(label)\n",
    "\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "    \n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True, dim=CFG.img_size):\n",
    "\n",
    "    def augment(image, DIM=dim):\n",
    "\n",
    "        if random_float() < CFG.transform_prob:\n",
    "            image = transform(image, DIM=DIM)\n",
    "\n",
    "        image = tf.image.random_flip_left_right(image) if CFG.hflip else image\n",
    "        image = tf.image.random_flip_up_down(image) if CFG.vflip else image\n",
    "\n",
    "        if random_float() < CFG.p_pixel_aug:\n",
    "            image = tf.image.random_contrast(image, CFG.cont[0], CFG.cont[1])\n",
    "            image = tf.image.random_brightness(image, CFG.bri)\n",
    "        \n",
    "        image = tf.clip_by_value(image, 0, 1)  if CFG.clip else image     \n",
    "        image = tf.reshape(image, [*DIM, 3])\n",
    "\n",
    "        return image\n",
    "\n",
    "    def augment_with_labels(image, label):\n",
    "\n",
    "        return augment(image), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "\n",
    "# https://qiita.com/Suguru_Toyohara/items/820b0dad955ecd91c7f3\n",
    "def build_dataset(paths, labels=None, batch_size=CFG.batch_size, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=False, shuffle=1024, \n",
    "                  cache_dir=\"\", drop_remainder=False):\n",
    "    \n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "\n",
    "    # https://tensorflow.classcat.com/2019/03/23/tf20-alpha-guide-data-performance/\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    ds = ds.cache(cache_dir) if cache else ds\n",
    "    ds = ds.repeat() if repeat else ds\n",
    "\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n",
    "\n",
    "    if augment and labels is not None:\n",
    "        ds = ds.map(lambda image, label: (dropout(image,\n",
    "                                                  DIM=CFG.img_size, \n",
    "                                                  PROBABILITY=CFG.drop_prob, \n",
    "                                                  cutout=CFG.drop_cnt,\n",
    "                                                  size=CFG.drop_size), label),num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    \n",
    "    #if augment and labels is not None:\n",
    "    #    if CFG.cutmix_prob:\n",
    "    #        ds = ds.map(get_cutmix(alpha=CFG.cutmix_alpha,prob=CFG.cutmix_prob),num_parallel_calls=AUTO)\n",
    "    #    if CFG.mixup_prob:\n",
    "    #        ds = ds.map(get_mixup(alpha=CFG.mixup_alpha,prob=CFG.mixup_prob),num_parallel_calls=AUTO)\n",
    "    \n",
    "\n",
    "    ds = ds.prefetch(AUTO)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name=CFG.model_name, dim=CFG.img_size):\n",
    "\n",
    "\n",
    "        # backbone\n",
    "        base = getattr(efficientnet, model_name)(input_shape=(*dim,3), pretrained='imagenet', num_classes=0)\n",
    "\n",
    "        inp = base.inputs\n",
    "\n",
    "        x = base.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # necks\n",
    "        x_bowel = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_extra = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_liver = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_kidney = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_spleen = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "\n",
    "        # heads\n",
    "        out_bowel = tf.keras.layers.Dense(1, name='bowel', activation='sigmoid')(x_bowel)\n",
    "        out_extra = tf.keras.layers.Dense(1, name='extra', activation='sigmoid')(x_extra)\n",
    "        out_liver = tf.keras.layers.Dense(3, name='liver', activation='softmax')(x_liver)\n",
    "        out_kidney = tf.keras.layers.Dense(3, name='kidney', activation='softmax')(x_kidney)\n",
    "        out_spleen = tf.keras.layers.Dense(3, name='spleen', activation='softmax')(x_spleen)\n",
    "\n",
    "        out = [out_bowel, out_extra, out_liver, out_kidney, out_spleen]\n",
    "\n",
    "        model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n",
    "\n",
    "        loss = {'bowel':tf.keras.losses.BinaryCrossentropy(),\n",
    "                'extra':tf.keras.losses.BinaryCrossentropy(),\n",
    "                'liver':tf.keras.losses.CategoricalCrossentropy(),\n",
    "                'kidney':tf.keras.losses.CategoricalCrossentropy(),\n",
    "                'spleen':tf.keras.losses.CategoricalCrossentropy()}\n",
    "\n",
    "        metrics = {'bowel':'accuracy',\n",
    "                   'extra':'accuracy',\n",
    "                   'liver':'accuracy',\n",
    "                   'kidney':'accuracy',\n",
    "                   'spleen':'accuracy'}\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.LearningRateScheduler at 0x282b5f3a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the optimal lr is 10^-5 ish\n",
    "def get_lr_callback(batch_size=8, plot=False):\n",
    "\n",
    "    lr_min     = 0.000001\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "\n",
    "        lr = lr_min * (10 ** epoch)\n",
    "\n",
    "        return lr\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(np.arange(CFG.epochs), [lrfn(epoch) for epoch in np.arange(CFG.epochs)], marker='o')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('epoch'); plt.ylabel('learnig rate')\n",
    "        plt.title('Learning Rate Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "get_lr_callback(CFG.batch_size, plot=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "827/827 [==============================] - ETA: 0s - loss: 4.2644 - bowel_loss: 0.6990 - extra_loss: 0.6382 - liver_loss: 0.9093 - kidney_loss: 1.0002 - spleen_loss: 1.0177 - bowel_accuracy: 0.4907 - extra_accuracy: 0.7302 - liver_accuracy: 0.7954 - kidney_accuracy: 0.5758 - spleen_accuracy: 0.5864\n",
      "Epoch 1: val_loss improved from inf to 4.16936, saving model to fold-0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827/827 [==============================] - 955s 1s/step - loss: 4.2644 - bowel_loss: 0.6990 - extra_loss: 0.6382 - liver_loss: 0.9093 - kidney_loss: 1.0002 - spleen_loss: 1.0177 - bowel_accuracy: 0.4907 - extra_accuracy: 0.7302 - liver_accuracy: 0.7954 - kidney_accuracy: 0.5758 - spleen_accuracy: 0.5864 - val_loss: 4.1694 - val_bowel_loss: 0.6886 - val_extra_loss: 0.6520 - val_liver_loss: 0.8911 - val_kidney_loss: 0.9537 - val_spleen_loss: 0.9839 - val_bowel_accuracy: 0.5305 - val_extra_accuracy: 0.6718 - val_liver_accuracy: 0.7930 - val_kidney_accuracy: 0.7012 - val_spleen_accuracy: 0.6501 - lr: 1.0000e-06\n",
      "Epoch 2/3\n",
      "827/827 [==============================] - ETA: 0s - loss: 2.7808 - bowel_loss: 0.6357 - extra_loss: 0.4975 - liver_loss: 0.3719 - kidney_loss: 0.5319 - spleen_loss: 0.7437 - bowel_accuracy: 0.6398 - extra_accuracy: 0.7596 - liver_accuracy: 0.9206 - kidney_accuracy: 0.8232 - spleen_accuracy: 0.6827\n",
      "Epoch 2: val_loss improved from 4.16936 to 3.49361, saving model to fold-0.h5\n",
      "827/827 [==============================] - 753s 909ms/step - loss: 2.7808 - bowel_loss: 0.6357 - extra_loss: 0.4975 - liver_loss: 0.3719 - kidney_loss: 0.5319 - spleen_loss: 0.7437 - bowel_accuracy: 0.6398 - extra_accuracy: 0.7596 - liver_accuracy: 0.9206 - kidney_accuracy: 0.8232 - spleen_accuracy: 0.6827 - val_loss: 3.4936 - val_bowel_loss: 0.6854 - val_extra_loss: 0.5884 - val_liver_loss: 0.5747 - val_kidney_loss: 0.7481 - val_spleen_loss: 0.8970 - val_bowel_accuracy: 0.5686 - val_extra_accuracy: 0.6845 - val_liver_accuracy: 0.8279 - val_kidney_accuracy: 0.7721 - val_spleen_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 3/3\n",
      "827/827 [==============================] - ETA: 0s - loss: 1.0780 - bowel_loss: 0.2561 - extra_loss: 0.1976 - liver_loss: 0.1297 - kidney_loss: 0.2208 - spleen_loss: 0.2738 - bowel_accuracy: 0.8949 - extra_accuracy: 0.9202 - liver_accuracy: 0.9639 - kidney_accuracy: 0.9235 - spleen_accuracy: 0.9028\n",
      "Epoch 3: val_loss did not improve from 3.49361\n",
      "827/827 [==============================] - 782s 945ms/step - loss: 1.0780 - bowel_loss: 0.2561 - extra_loss: 0.1976 - liver_loss: 0.1297 - kidney_loss: 0.2208 - spleen_loss: 0.2738 - bowel_accuracy: 0.8949 - extra_accuracy: 0.9202 - liver_accuracy: 0.9639 - kidney_accuracy: 0.9235 - spleen_accuracy: 0.9028 - val_loss: 5.1066 - val_bowel_loss: 0.8197 - val_extra_loss: 1.2081 - val_liver_loss: 0.8891 - val_kidney_loss: 0.8655 - val_spleen_loss: 1.3242 - val_bowel_accuracy: 0.7381 - val_extra_accuracy: 0.6553 - val_liver_accuracy: 0.7807 - val_kidney_accuracy: 0.8024 - val_spleen_accuracy: 0.6329 - lr: 1.0000e-04\n",
      "FOLD 0 RESULTS\n",
      "BEST Loss  : 3.494\n",
      "BEST Acc   : 0.699\n",
      "BEST Epoch : 1\n",
      "Bowel : 0.569\n",
      "Extravasation : 0.684\n",
      "Liver: 0.828\n",
      "Kidney: 0.772\n",
      "Spleen: 0.643\n",
      "\n",
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "801/801 [==============================] - ETA: 0s - loss: 4.3720 - bowel_loss: 0.6851 - extra_loss: 0.6664 - liver_loss: 0.9852 - kidney_loss: 1.0145 - spleen_loss: 1.0207 - bowel_accuracy: 0.5656 - extra_accuracy: 0.6451 - liver_accuracy: 0.6915 - kidney_accuracy: 0.5750 - spleen_accuracy: 0.5711\n",
      "Epoch 1: val_loss improved from inf to 4.19333, saving model to fold-1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 1010s 1s/step - loss: 4.3720 - bowel_loss: 0.6851 - extra_loss: 0.6664 - liver_loss: 0.9852 - kidney_loss: 1.0145 - spleen_loss: 1.0207 - bowel_accuracy: 0.5656 - extra_accuracy: 0.6451 - liver_accuracy: 0.6915 - kidney_accuracy: 0.5750 - spleen_accuracy: 0.5711 - val_loss: 4.1933 - val_bowel_loss: 0.6865 - val_extra_loss: 0.6535 - val_liver_loss: 0.8924 - val_kidney_loss: 0.9472 - val_spleen_loss: 1.0138 - val_bowel_accuracy: 0.5462 - val_extra_accuracy: 0.7078 - val_liver_accuracy: 0.8704 - val_kidney_accuracy: 0.6917 - val_spleen_accuracy: 0.5919 - lr: 1.0000e-06\n",
      "Epoch 2/3\n",
      "801/801 [==============================] - ETA: 0s - loss: 2.9005 - bowel_loss: 0.6082 - extra_loss: 0.5486 - liver_loss: 0.5345 - kidney_loss: 0.5082 - spleen_loss: 0.7009 - bowel_accuracy: 0.6876 - extra_accuracy: 0.7017 - liver_accuracy: 0.8413 - kidney_accuracy: 0.8347 - spleen_accuracy: 0.7151\n",
      "Epoch 2: val_loss improved from 4.19333 to 3.23144, saving model to fold-1.h5\n",
      "801/801 [==============================] - 854s 1s/step - loss: 2.9005 - bowel_loss: 0.6082 - extra_loss: 0.5486 - liver_loss: 0.5345 - kidney_loss: 0.5082 - spleen_loss: 0.7009 - bowel_accuracy: 0.6876 - extra_accuracy: 0.7017 - liver_accuracy: 0.8413 - kidney_accuracy: 0.8347 - spleen_accuracy: 0.7151 - val_loss: 3.2314 - val_bowel_loss: 0.6847 - val_extra_loss: 0.5528 - val_liver_loss: 0.3929 - val_kidney_loss: 0.6433 - val_spleen_loss: 0.9576 - val_bowel_accuracy: 0.5991 - val_extra_accuracy: 0.7127 - val_liver_accuracy: 0.9150 - val_kidney_accuracy: 0.7801 - val_spleen_accuracy: 0.6356 - lr: 1.0000e-05\n",
      "Epoch 3/3\n",
      "801/801 [==============================] - ETA: 0s - loss: 1.2527 - bowel_loss: 0.2455 - extra_loss: 0.2331 - liver_loss: 0.2445 - kidney_loss: 0.2031 - spleen_loss: 0.3264 - bowel_accuracy: 0.9022 - extra_accuracy: 0.9052 - liver_accuracy: 0.9196 - kidney_accuracy: 0.9339 - spleen_accuracy: 0.8805\n",
      "Epoch 3: val_loss did not improve from 3.23144\n",
      "801/801 [==============================] - 896s 1s/step - loss: 1.2527 - bowel_loss: 0.2455 - extra_loss: 0.2331 - liver_loss: 0.2445 - kidney_loss: 0.2031 - spleen_loss: 0.3264 - bowel_accuracy: 0.9022 - extra_accuracy: 0.9052 - liver_accuracy: 0.9196 - kidney_accuracy: 0.9339 - spleen_accuracy: 0.8805 - val_loss: 4.7333 - val_bowel_loss: 0.8647 - val_extra_loss: 0.8279 - val_liver_loss: 0.5674 - val_kidney_loss: 0.9214 - val_spleen_loss: 1.5518 - val_bowel_accuracy: 0.6638 - val_extra_accuracy: 0.6339 - val_liver_accuracy: 0.8228 - val_kidney_accuracy: 0.7553 - val_spleen_accuracy: 0.5757 - lr: 1.0000e-04\n",
      "FOLD 1 RESULTS\n",
      "BEST Loss  : 3.231\n",
      "BEST Acc   : 0.729\n",
      "BEST Epoch : 1\n",
      "Bowel : 0.599\n",
      "Extravasation : 0.713\n",
      "Liver: 0.915\n",
      "Kidney: 0.780\n",
      "Spleen: 0.636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold in np.arange(CFG.folds):\n",
    "\n",
    "    train_df = df.query(\"fold!=@fold\")\n",
    "    valid_df = df.query(\"fold==@fold\")\n",
    "\n",
    "    train_paths  = train_df.image_path.values\n",
    "    train_labels = train_df[CFG.target_col].values.astype(np.float32)\n",
    "    valid_paths  = valid_df.image_path.values\n",
    "    valid_labels = valid_df[CFG.target_col].values.astype(np.float32)\n",
    "    test_paths   = test_df.image_path.values\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = build_model(CFG.model_name, dim=CFG.img_size)\n",
    "\n",
    "    train_ds = build_dataset(train_paths, train_labels)\n",
    "    valid_ds = build_dataset(valid_paths, valid_labels)\n",
    "\n",
    "    callbacks = []\n",
    "    ## save best model after each fold\n",
    "    save = tf.keras.callbacks.ModelCheckpoint('fold-%i.h5'%fold, monitor='val_loss', \n",
    "                                              verbose=1, save_best_only=True,\n",
    "                                              save_weights_only=False, mode='min', save_freq='epoch')\n",
    "    callbacks +=[save]\n",
    "    callbacks += [get_lr_callback(CFG.batch_size)]\n",
    "\n",
    "\n",
    "    history = model.fit(train_ds, validation_data = valid_ds, \n",
    "                        epochs=CFG.epochs, steps_per_epoch=None, \n",
    "                        callbacks = callbacks, max_queue_size=1, verbose=1)\n",
    "                        \n",
    "    best_epoch = np.argmin(history.history['val_loss'])\n",
    "    best_loss = history.history['val_loss'][best_epoch]\n",
    "    best_acc_bowel = history.history['val_bowel_accuracy'][best_epoch]\n",
    "    best_acc_extra = history.history['val_extra_accuracy'][best_epoch]\n",
    "    best_acc_liver = history.history['val_liver_accuracy'][best_epoch]\n",
    "    best_acc_kidney = history.history['val_kidney_accuracy'][best_epoch]\n",
    "    best_acc_spleen = history.history['val_spleen_accuracy'][best_epoch]\n",
    "\n",
    "    best_acc = np.mean([best_acc_bowel, best_acc_extra, best_acc_liver, best_acc_kidney, best_acc_spleen])\n",
    "    print(f'FOLD {fold} RESULTS')\n",
    "    print(f'BEST Loss  : {best_loss:.3f}\\nBEST Acc   : {best_acc:.3f}\\nBEST Epoch : {best_epoch}')\n",
    "    print(f'Bowel : {best_acc_bowel:.3f}')\n",
    "    print(f'Extravasation : {best_acc_extra:.3f}')\n",
    "    print(f'Liver: {best_acc_liver:.3f}')\n",
    "    print(f'Kidney: {best_acc_kidney:.3f}')\n",
    "    print(f'Spleen: {best_acc_spleen:.3f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_proc(pred):\n",
    "    argmax = np.argmax(pred, axis=1).astype('uint8')\n",
    "    one_hot = tf.keras.utils.to_categorical(argmax, num_classes=3)\n",
    "    return one_hot.astype('uint8')\n",
    "\n",
    "def sc_proc(pred, thr=0.5):\n",
    "    proc_pred = (pred > thr).astype('uint8')\n",
    "    return proc_pred\n",
    "\n",
    "def post_proc(pred):\n",
    "    proc_pred = np.empty((pred.shape[0], 2*2 + 3*3), dtype='float32')\n",
    "\n",
    "    proc_pred[:, 0] = 1 - pred[:, 0] # bowel-healthy\n",
    "    proc_pred[:, 1] = pred[:, 0] # bowel-injured\n",
    "    proc_pred[:, 2] = 1 - pred[:, 1] # extra-healthy\n",
    "    proc_pred[:, 3] = pred[:, 1] # extra-injured\n",
    "    \n",
    "    proc_pred[:, 4:7] = pred[:, 2:5] # liver\n",
    "    proc_pred[:, 7:10] = pred[:, 5:8] # kidney\n",
    "    proc_pred[:, 10:13] = pred[:, 8:11] # spleen\n",
    "\n",
    "    return proc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[512, 512], ['./fold-0.h5', './fold-1.h5']]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPT_DIRS = [\n",
    "    ([512, 512], './'),\n",
    "]\n",
    "\n",
    "MODEL_CONFIGS = []\n",
    "for img_size, ckpt_dir in  CKPT_DIRS:\n",
    "    paths = sorted(glob(os.path.join(ckpt_dir, '*h5')))[0:CFG.folds]\n",
    "    if len(paths)==0:\n",
    "        print('no model found for :',base_dir)\n",
    "    MODEL_CONFIGS.append([img_size, paths])\n",
    "display(MODEL_CONFIGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 48843\n",
      "1/1 [==============================] - 16s 16s/step\n",
      "1/1 [==============================] - 15s 15s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:36, 36.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 50046\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 18s 18s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:14, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 63706\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 17s 17s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:52, 37.42s/it]\n"
     ]
    }
   ],
   "source": [
    "patient_ids = test_df['patient_id'].unique()\n",
    "\n",
    "patient_ids.sort()\n",
    "\n",
    "patient_preds = np.zeros(shape=(len(patient_ids), 2*2 + 3*3), dtype='float32')\n",
    "\n",
    "preds = np.zeros(shape=(1, 11), dtype=np.float32)\n",
    "\n",
    "for pidx, patient_id in tqdm(enumerate(patient_ids)):\n",
    "\n",
    "    patient_df = test_df[test_df['patient_id'] != patient_id]\n",
    "\n",
    "    model_preds = np.zeros(shape=(1, 11), dtype=np.float32)\n",
    "\n",
    "    print(f'Patient ID: {patient_id}')\n",
    "\n",
    "    for midx, (img_size, fold_paths) in enumerate(MODEL_CONFIGS):\n",
    "\n",
    "        patient_paths = patient_df.image_path.tolist()\n",
    "\n",
    "        min_batchsize = len(patient_paths)\n",
    "        CFG.batch_size = min(min_batchsize, CFG.batch_size)\n",
    "\n",
    "        dtest = build_dataset(patient_paths, batch_size=CFG.batch_size, repeat=False, \n",
    "                             shuffle=False, augment=False, cache=False,\n",
    "                             decode_fn=build_decoder(with_labels=False, target_size=CFG.img_size),)\n",
    "        \n",
    "        for fold_path in fold_paths:\n",
    "            \n",
    "            model = tf.keras.models.load_model(fold_path, compile=False)\n",
    "             \n",
    "            pred = model.predict(dtest, verbose=1)\n",
    "            pred = np.concatenate(pred, axis=-1).astype('float32')\n",
    "            pred = pred[:len(patient_paths), :]\n",
    "            pred = np.mean(pred.reshape(1, len(patient_paths), 11), axis=0)\n",
    "            pred = np.max(pred, axis=0) # taking max prediction of all ct scans for a patient\n",
    "\n",
    "            model_preds += pred / (len(fold_paths)*len(MODEL_CONFIGS))\n",
    "                                   \n",
    "            del model, pred; gc.collect()\n",
    "        \n",
    "        del dtest, patient_paths; gc.collect()\n",
    "\n",
    "        patient_preds[pidx, :] += post_proc(model_preds)[0]\n",
    "\n",
    "    del model_preds; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39961112, 0.6003889 , 0.19832367, 0.80167633, 0.8279312 ,\n",
       "        0.1554491 , 0.1539712 , 0.8377094 , 0.25589496, 0.12820704,\n",
       "        0.48305714, 0.21906379, 0.32214224],\n",
       "       [0.37850815, 0.62149185, 0.20995879, 0.7900412 , 0.8738221 ,\n",
       "        0.1554491 , 0.1539712 , 0.8490353 , 0.25589496, 0.12820704,\n",
       "        0.6941439 , 0.2201896 , 0.32214224],\n",
       "       [0.3867665 , 0.6132335 , 0.15467894, 0.84532106, 0.8738221 ,\n",
       "        0.09857767, 0.08143379, 0.91211593, 0.14850247, 0.07686877,\n",
       "        0.6941439 , 0.21581322, 0.30262697]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Dataset/test_images/50046/24574/30.png</td>\n",
       "      <td>50046</td>\n",
       "      <td>24574</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Dataset/test_images/63706/39279/30.png</td>\n",
       "      <td>63706</td>\n",
       "      <td>39279</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Dataset/test_images/48843/62825/30.png</td>\n",
       "      <td>48843</td>\n",
       "      <td>62825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_path  patient_id  series_id  \\\n",
       "0  ./Dataset/test_images/50046/24574/30.png       50046      24574   \n",
       "1  ./Dataset/test_images/63706/39279/30.png       63706      39279   \n",
       "2  ./Dataset/test_images/48843/62825/30.png       48843      62825   \n",
       "\n",
       "   instance_number  \n",
       "0               30  \n",
       "1               30  \n",
       "2               30  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'patient_id':patient_ids,})\n",
    "\n",
    "sub_df = pd.read_csv('./sample_submission.csv')\n",
    "pred_df = pred_df.merge(sub_df, on='patient_id', how='right')\n",
    "\n",
    "for i, row in enumerate(patient_preds):\n",
    "    pred_df.loc[i, 'bowel_healthy'] = row[0]\n",
    "    pred_df.loc[i, 'bowel_injury'] = row[1]\n",
    "    pred_df.loc[i, 'extravasation_healthy'] = row[2]\n",
    "    pred_df.loc[i, 'extravasation_injury'] = row[3]\n",
    "    pred_df.loc[i, 'kidney_healthy'] = row[4]\n",
    "    pred_df.loc[i, 'kidney_low'] = row[5]\n",
    "    pred_df.loc[i, 'kidney_high'] = row[6]\n",
    "    pred_df.loc[i, 'liver_healthy'] = row[7]\n",
    "    pred_df.loc[i, 'liver_low'] = row[8]\n",
    "    pred_df.loc[i, 'liver_high'] = row[9]\n",
    "    pred_df.loc[i, 'spleen_healthy'] = row[10]\n",
    "    pred_df.loc[i, 'spleen_low'] = row[11]\n",
    "    pred_df.loc[i, 'spleen_high'] = row[12]\n",
    "\n",
    "pred_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48843</td>\n",
       "      <td>0.399611</td>\n",
       "      <td>0.600389</td>\n",
       "      <td>0.198324</td>\n",
       "      <td>0.801676</td>\n",
       "      <td>0.827931</td>\n",
       "      <td>0.155449</td>\n",
       "      <td>0.153971</td>\n",
       "      <td>0.837709</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>0.483057</td>\n",
       "      <td>0.219064</td>\n",
       "      <td>0.322142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50046</td>\n",
       "      <td>0.378508</td>\n",
       "      <td>0.621492</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>0.790041</td>\n",
       "      <td>0.873822</td>\n",
       "      <td>0.155449</td>\n",
       "      <td>0.153971</td>\n",
       "      <td>0.849035</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>0.694144</td>\n",
       "      <td>0.220190</td>\n",
       "      <td>0.322142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63706</td>\n",
       "      <td>0.386766</td>\n",
       "      <td>0.613234</td>\n",
       "      <td>0.154679</td>\n",
       "      <td>0.845321</td>\n",
       "      <td>0.873822</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.081434</td>\n",
       "      <td>0.912116</td>\n",
       "      <td>0.148502</td>\n",
       "      <td>0.076869</td>\n",
       "      <td>0.694144</td>\n",
       "      <td>0.215813</td>\n",
       "      <td>0.302627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0       48843       0.399611      0.600389               0.198324   \n",
       "1       50046       0.378508      0.621492               0.209959   \n",
       "2       63706       0.386766      0.613234               0.154679   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.801676        0.827931    0.155449     0.153971   \n",
       "1              0.790041        0.873822    0.155449     0.153971   \n",
       "2              0.845321        0.873822    0.098578     0.081434   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.837709   0.255895    0.128207        0.483057    0.219064   \n",
       "1       0.849035   0.255895    0.128207        0.694144    0.220190   \n",
       "2       0.912116   0.148502    0.076869        0.694144    0.215813   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.322142  \n",
       "1     0.322142  \n",
       "2     0.302627  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsna2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
