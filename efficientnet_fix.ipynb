{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import math\n",
    "import tensorflow.keras.backend as K\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from keras_cv_attention_models import efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    model_name = 'EfficientNetV2B0'\n",
    "\n",
    "    batch_size = 32\n",
    "    \n",
    "    epochs = 4\n",
    "\n",
    "    folds = 4\n",
    "\n",
    "    seed = 123\n",
    "\n",
    "    img_size = [256, 256]\n",
    "\n",
    "    augment   = True\n",
    "\n",
    "    transform_prob = 0.90\n",
    "    fill_mode = 'constant'\n",
    "    rot    = 2.0\n",
    "    shr    = 4.0\n",
    "    hzoom  = 50.0\n",
    "    wzoom  = 50.0\n",
    "    hshift = 30.0\n",
    "    wshift = 30.0\n",
    "\n",
    "    hflip = True\n",
    "    vflip = True\n",
    "\n",
    "    p_pixel_aug = 0.90\n",
    "    cont = [0.5, 2]\n",
    "    bri  = 0.5\n",
    "\n",
    "    clip = False\n",
    "\n",
    "    drop_prob   = 0.6\n",
    "    drop_cnt    = 10\n",
    "    drop_size   = 0.05\n",
    "\n",
    "    mixup_prob = 0.5\n",
    "    mixup_alpha = 0.2\n",
    "    \n",
    "    cutmix_prob = 0.5\n",
    "    cutmix_alpha = 2.5\n",
    "\n",
    "    target_col  = [ \"bowel_injury\", \"extravasation_injury\", \"kidney_healthy\", \"kidney_low\",\n",
    "                   \"kidney_high\", \"liver_healthy\", \"liver_low\", \"liver_high\",\n",
    "                   \"spleen_healthy\", \"spleen_low\", \"spleen_high\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding done!!!\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    print('seeding done!!!')\n",
    "\n",
    "seeding(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('./Dataset/test.csv')\n",
    "test_df['image_path'] = (f'./Dataset/test_images/'\n",
    "                          + test_df.patient_id.astype(str)+ '/' \n",
    "                          + test_df.series_id.astype(str) + '/' \n",
    "                          + test_df.instance_number.astype(str) \n",
    "                          + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asign Fold numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold  patient_id\n",
       "0.0   4353           43\n",
       "      5649           10\n",
       "      6962            4\n",
       "      7026           26\n",
       "      7482           77\n",
       "                   ... \n",
       "3.0   56981          68\n",
       "      58324           9\n",
       "      60993          29\n",
       "      63113         362\n",
       "      65456          16\n",
       "Length: 246, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['stratify'] = ''\n",
    "\n",
    "for col in CFG.target_col:\n",
    "    df['stratify'] += df[col].astype(str)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for  fold , (train_idx, val_idx) in enumerate(sgkf.split(df, df['stratify'], df['patient_id'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "display(df.groupby(['fold', 'patient_id']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int(shape=[], minval=0, maxval=1):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "def random_float(shape=[], minval=0.0, maxval=1.0):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "# make affine transformation matrix\n",
    "# https://cs.kwansei.ac.jp/prog1/affine.html\n",
    "def get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "\n",
    "    # degrees to radians\n",
    "    shear = math.pi * shear / 180.\n",
    "\n",
    "\n",
    "    def get_3x3_mat(list):\n",
    "        return tf.reshape(tf.concat([list], axis=0), [3, 3])\n",
    "    \n",
    "\n",
    "    one = tf.constant([1], dtype='float32')\n",
    "    zero = tf.constant([0], dtype='float32')\n",
    "\n",
    "    # for shear matrix\n",
    "    cos = tf.math.cos(shear)\n",
    "    sin = tf.math.sin(shear)\n",
    "\n",
    "    shear_matrix = get_3x3_mat([one,  sin,  zero,\n",
    "                                zero, cos,  zero,\n",
    "                                zero, zero, one])\n",
    "    \n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero,\n",
    "                               zero,            one/width_zoom, zero,\n",
    "                               zero,            zero,           one])\n",
    "    \n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    #ã€€return composite transformation\n",
    "    return K.dot(shear_matrix, K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "\n",
    "# apply affine transformation\n",
    "def transform(image, DIM=CFG.img_size):\n",
    "\n",
    "    # add padding to align image sizes\n",
    "    if DIM[0]>DIM[1]:\n",
    "        diff  = (DIM[0]-DIM[1])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[0, 0], [pad[0], pad[1]],[0, 0]])\n",
    "        NEW_DIM = DIM[0]\n",
    "\n",
    "    elif DIM[0]<DIM[1]:\n",
    "        diff  = (DIM[1]-DIM[0])\n",
    "        pad   = [diff//2, diff//2 + diff%2]\n",
    "        image = tf.pad(image, [[pad[0], pad[1]], [0, 0],[0, 0]])\n",
    "        NEW_DIM = DIM[1]\n",
    "    \n",
    "    rotation     = CFG.rot * tf.random.normal([1], dtype='float32')\n",
    "    shear        = CFG.shr * tf.random.normal([1], dtype='float32')\n",
    "    height_zoom  = 1.0 + tf.random.normal([1], dtype='float32') / CFG.hzoom\n",
    "    width_zoom   = 1.0 + tf.random.normal([1], dtype='float32') / CFG.wzoom\n",
    "    height_shift = CFG.hshift * tf.random.normal([1], dtype='float32') \n",
    "    width_shift  = CFG.wshift * tf.random.normal([1], dtype='float32')\n",
    "\n",
    "    # inverse of get_matrix\n",
    "    # https://daeudaeu.com/reverse-matorix/\n",
    "    transformation_matrix     =tf.linalg.inv(get_matrix(shear, height_zoom, width_zoom, height_shift, width_shift))\n",
    "    transformation_matrix_flat=tfa.image.transform_ops.matrices_to_flat_transforms(transformation_matrix)\n",
    "\n",
    "    # apply affine transformation to image\n",
    "    image=tfa.image.transform(image, transformation_matrix_flat, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # rotate image\n",
    "    image=tfa.image.rotate(image, -rotation, fill_mode=CFG.fill_mode)\n",
    "\n",
    "    # remove padding\n",
    "    if DIM[0]>DIM[1]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,3])\n",
    "        image = image[:, pad[0]:-pad[1],:]\n",
    "    elif DIM[1]>DIM[0]:\n",
    "        image=tf.reshape(image, [NEW_DIM, NEW_DIM,3])\n",
    "        image = image[pad[0]:-pad[1],:,:]\n",
    "\n",
    "    # align image sizes\n",
    "    image = tf.reshape(image, [*DIM, 3])  \n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# apply dropout to image\n",
    "def dropout(image,DIM=CFG.img_size, PROBABILITY = 0.6, cutout = 5, size = 0.1):\n",
    "\n",
    "    # boolean to int\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "\n",
    "    if (P==0) or (cutout==0) or (size==0):\n",
    "        return image\n",
    "    \n",
    "    for c in range(cutout):\n",
    "\n",
    "        # choose random coordinates\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM[1]),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM[0]),tf.int32)\n",
    "\n",
    "        # determine cutout square\n",
    "        width = tf.cast(size*min(DIM),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-width//2)\n",
    "        yb = tf.math.minimum(DIM[0],y+width//2)\n",
    "        xa = tf.math.maximum(0,x-width//2)\n",
    "        xb = tf.math.minimum(DIM[1],x+width//2)\n",
    "\n",
    "        # image after cutout\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3], dtype = image.dtype) # cutouted square\n",
    "        three = image[ya:yb,xb:DIM[1],:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM[0],:,:]],axis=0)\n",
    "        image = tf.reshape(image,[*DIM,3])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# apply mixup amd cutmix to image\n",
    "# https://cvml-expertguide.net/terms/dl/regularization/data-augmentation/\n",
    "# mixup\n",
    "def get_mixup(alpha, prob):\n",
    "    \n",
    "    \n",
    "    # https://qiita.com/AseiSugiyama/items/66a75610c569a23ac493\n",
    "    @tf.function\n",
    "    def mixup(images, labels, alpha=alpha, prob=prob):\n",
    "\n",
    "        if random_float() > prob:\n",
    "            return images, labels\n",
    "        \n",
    "        image_shape = tf.shape(images)\n",
    "        label_shape = tf.shape(labels) # label shape has (20,1) and (20,3) mixed in it so can't get the shape\n",
    "\n",
    "        beta = tfp.distributions.Beta(alpha, alpha)\n",
    "        lamb = beta.sample(1)[0]\n",
    "\n",
    "        images = lamb * images + (1.0 - lamb) * tf.roll(images, shift=1, axis=0)\n",
    "        labels = lamb * labels + (1.0 - lamb) * tf.roll(labels, shift=1, axis=0)\n",
    "\n",
    "        images = tf.reshape(images, image_shape)\n",
    "        labels = tf.reshape(labels, label_shape)\n",
    "\n",
    "        return images, labels\n",
    "    \n",
    "    return mixup\n",
    "\n",
    "\n",
    "\n",
    "# cutmix\n",
    "def get_cutmix(alpha, prob):\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def cutmix(images, labels, alpha=alpha, prob=prob):\n",
    "\n",
    "        if random_float() > prob:\n",
    "            return images, labels\n",
    "        \n",
    "        image_shape = tf.shape(images)\n",
    "        label_shape = tf.shape(labels) # label shape has (20,1) and (20,3) mixed in it so can't get the shape\n",
    "\n",
    "        width = tf.cast(image_shape[2], tf.int32)\n",
    "        height = tf.cast(image_shape[1], tf.int32)\n",
    "\n",
    "        beta = tfp.distributions.Beta(alpha, alpha)\n",
    "        lamb = beta.sample(1)[0]\n",
    "\n",
    "        r_x = random_int([], minval=0, maxval=width)\n",
    "        r_y = random_int([], minval=0, maxval=height)\n",
    "        r = 0.5 * tf.math.sqrt(1.0 - lamb)\n",
    "        r_w_half = tf.cast(r * tf.cast(width, tf.float32), tf.int32)\n",
    "        r_h_half = tf.cast(r * tf.cast(height, tf.float32), tf.int32)\n",
    "\n",
    "        x1 = tf.cast(tf.clip_by_value(r_x - r_w_half, 0, width), tf.int32)\n",
    "        x2 = tf.cast(tf.clip_by_value(r_x + r_w_half, 0, width), tf.int32)\n",
    "        y1 = tf.cast(tf.clip_by_value(r_y - r_h_half, 0, height), tf.int32)\n",
    "        y2 = tf.cast(tf.clip_by_value(r_y + r_h_half, 0, height), tf.int32)\n",
    "\n",
    "        # outer-pad patch -> [0, 0, 1, 1, 0, 0]\n",
    "        patch1 = images[:, y1:y2, x1:x2, :]  # [batch, height, width, channel]\n",
    "        patch1 = tf.pad(patch1, [[0, 0], [y1, height - y2], [x1, width - x2], [0, 0]])  # outer-pad\n",
    "\n",
    "        # inner-pad patch -> [1, 1, 0, 0, 1, 1]\n",
    "        patch2 = tf.roll(images, shift=1, axis=0)[:, y1:y2, x1:x2, :]\n",
    "        patch2 = tf.pad(patch2, [[0, 0], [y1, height - y2], [x1, width - x2], [0, 0]])\n",
    "        patch2 = tf.roll(images, shift=1, axis=0) - patch2  # inner-pad = img - outer-pad\n",
    "\n",
    "        images = patch1 + patch2  # cutmix img\n",
    "\n",
    "        lambda2 = tf.cast((1.0 - (x2 - x1) * (y2 - y1) / (width * height)), tf.float32)\n",
    "        labels = lambda2 * labels + (1.0 - lambda2) * tf.roll(labels, shift=1, axis=0)\n",
    "\n",
    "        images = tf.reshape(images, image_shape)\n",
    "        labels = tf.reshape(labels, label_shape)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    return cutmix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pipeline\n",
    "1. Reads the PNG file and then decode it to tf.tensor\n",
    "2. Resizes the image\n",
    "3. Changes the datatype to float32\n",
    "4. Cache the data for boosting up the speed\n",
    "5. Apply augmentations \n",
    "6. Split the data into baches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(with_labels=True, target_size=CFG.img_size):\n",
    "\n",
    "\n",
    "    def decode_image(path):\n",
    "\n",
    "        file_binary = tf.io.read_file(path)\n",
    "        image = tf.image.decode_png(file_binary, channels=3, dtype=tf.uint8)\n",
    "        image = tf.image.resize(image, CFG.img_size, method='bilinear')\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = tf.reshape(image, [*CFG.img_size, 3])\n",
    "\n",
    "        return image\n",
    "    \n",
    "\n",
    "    def decode_label(label):\n",
    "        \n",
    "        label = tf.cast(label, tf.float32)\n",
    "        \n",
    "        return (label[0:1], label[1:2], label[2:5], label[5:8], label[8:11])\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "\n",
    "        return decode_image(path), decode_label(label)\n",
    "\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "    \n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True, dim=CFG.img_size):\n",
    "\n",
    "    def augment(image, DIM=dim):\n",
    "\n",
    "        if random_float() < CFG.transform_prob:\n",
    "            image = transform(image, DIM=DIM)\n",
    "\n",
    "        image = tf.image.random_flip_left_right(image) if CFG.hflip else image\n",
    "        image = tf.image.random_flip_up_down(image) if CFG.vflip else image\n",
    "\n",
    "        if random_float() < CFG.p_pixel_aug:\n",
    "            image = tf.image.random_contrast(image, CFG.cont[0], CFG.cont[1])\n",
    "            image = tf.image.random_brightness(image, CFG.bri)\n",
    "        \n",
    "        image = tf.clip_by_value(image, 0, 1)  if CFG.clip else image     \n",
    "        image = tf.reshape(image, [*DIM, 3])\n",
    "\n",
    "        return image\n",
    "\n",
    "    def augment_with_labels(image, label):\n",
    "\n",
    "        return augment(image), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "\n",
    "# https://qiita.com/Suguru_Toyohara/items/820b0dad955ecd91c7f3\n",
    "def build_dataset(paths, labels=None, batch_size=CFG.batch_size, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=False, shuffle=1024, \n",
    "                  cache_dir=\"\", drop_remainder=False):\n",
    "    \n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "\n",
    "    # https://tensorflow.classcat.com/2019/03/23/tf20-alpha-guide-data-performance/\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    ds = ds.cache(cache_dir) if cache else ds\n",
    "    ds = ds.repeat() if repeat else ds\n",
    "\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n",
    "\n",
    "    if augment and labels is not None:\n",
    "        ds = ds.map(lambda image, label: (dropout(image,\n",
    "                                                  DIM=CFG.img_size, \n",
    "                                                  PROBABILITY=CFG.drop_prob, \n",
    "                                                  cutout=CFG.drop_cnt,\n",
    "                                                  size=CFG.drop_size), label),num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    \n",
    "    #if augment and labels is not None:\n",
    "    #    if CFG.cutmix_prob:\n",
    "    #        ds = ds.map(get_cutmix(alpha=CFG.cutmix_alpha,prob=CFG.cutmix_prob),num_parallel_calls=AUTO)\n",
    "    #    if CFG.mixup_prob:\n",
    "    #        ds = ds.map(get_mixup(alpha=CFG.mixup_alpha,prob=CFG.mixup_prob),num_parallel_calls=AUTO)\n",
    "    \n",
    "\n",
    "    ds = ds.prefetch(AUTO)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name=CFG.model_name, dim=CFG.img_size):\n",
    "\n",
    "\n",
    "        # backbone\n",
    "        base = getattr(efficientnet, model_name)(input_shape=(*dim,3), pretrained='imagenet', num_classes=0)\n",
    "\n",
    "        inp = base.inputs\n",
    "\n",
    "        x = base.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # necks\n",
    "        x_bowel = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_extra = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_liver = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_kidney = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "        x_spleen = tf.keras.layers.Dense(32, activation='silu')(x)\n",
    "\n",
    "        # heads\n",
    "        out_bowel = tf.keras.layers.Dense(1, name='bowel', activation='sigmoid')(x_bowel)\n",
    "        out_extra = tf.keras.layers.Dense(1, name='extra', activation='sigmoid')(x_extra)\n",
    "        out_liver = tf.keras.layers.Dense(3, name='liver', activation='softmax')(x_liver)\n",
    "        out_kidney = tf.keras.layers.Dense(3, name='kidney', activation='softmax')(x_kidney)\n",
    "        out_spleen = tf.keras.layers.Dense(3, name='spleen', activation='softmax')(x_spleen)\n",
    "\n",
    "        out = [out_bowel, out_extra, out_liver, out_kidney, out_spleen]\n",
    "\n",
    "        model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n",
    "\n",
    "        loss = {'bowel':tf.keras.losses.BinaryCrossentropy(),\n",
    "                'extra':tf.keras.losses.BinaryCrossentropy(),\n",
    "                'liver':tf.keras.losses.CategoricalCrossentropy(),\n",
    "                'kidney':tf.keras.losses.CategoricalCrossentropy(),\n",
    "                'spleen':tf.keras.losses.CategoricalCrossentropy()}\n",
    "\n",
    "        metrics = {'bowel':'accuracy',\n",
    "                   'extra':'accuracy',\n",
    "                   'liver':'accuracy',\n",
    "                   'kidney':'accuracy',\n",
    "                   'spleen':'accuracy'}\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.LearningRateScheduler at 0x107e0d6c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the optimal lr is 10^-5 ish\n",
    "def get_lr_callback(batch_size=8, plot=False):\n",
    "\n",
    "    lr_min     = 0.000001\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "\n",
    "        lr = lr_min * (10 ** epoch)\n",
    "\n",
    "        return lr\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(np.arange(CFG.epochs), [lrfn(epoch) for epoch in np.arange(CFG.epochs)], marker='o')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('epoch'); plt.ylabel('learnig rate')\n",
    "        plt.title('Learning Rate Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "get_lr_callback(CFG.batch_size, plot=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "299/299 [==============================] - ETA: 0s - loss: 4.5894 - bowel_loss: 0.7065 - extra_loss: 0.6654 - liver_loss: 1.0180 - kidney_loss: 1.1318 - spleen_loss: 1.0677 - bowel_accuracy: 0.4925 - extra_accuracy: 0.6279 - liver_accuracy: 0.5236 - kidney_accuracy: 0.2828 - spleen_accuracy: 0.4383\n",
      "Epoch 1: val_loss improved from inf to 4.57731, saving model to fold-0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 326s 906ms/step - loss: 4.5894 - bowel_loss: 0.7065 - extra_loss: 0.6654 - liver_loss: 1.0180 - kidney_loss: 1.1318 - spleen_loss: 1.0677 - bowel_accuracy: 0.4925 - extra_accuracy: 0.6279 - liver_accuracy: 0.5236 - kidney_accuracy: 0.2828 - spleen_accuracy: 0.4383 - val_loss: 4.5773 - val_bowel_loss: 0.7123 - val_extra_loss: 0.6848 - val_liver_loss: 1.0408 - val_kidney_loss: 1.1042 - val_spleen_loss: 1.0352 - val_bowel_accuracy: 0.4870 - val_extra_accuracy: 0.5620 - val_liver_accuracy: 0.4936 - val_kidney_accuracy: 0.3365 - val_spleen_accuracy: 0.5157 - lr: 1.0000e-07\n",
      "Epoch 2/3\n",
      "299/299 [==============================] - ETA: 0s - loss: 4.4660 - bowel_loss: 0.7022 - extra_loss: 0.6549 - liver_loss: 0.9667 - kidney_loss: 1.0919 - spleen_loss: 1.0504 - bowel_accuracy: 0.5036 - extra_accuracy: 0.6646 - liver_accuracy: 0.6403 - kidney_accuracy: 0.3510 - spleen_accuracy: 0.4748\n",
      "Epoch 2: val_loss improved from 4.57731 to 4.39965, saving model to fold-0.h5\n",
      "299/299 [==============================] - 202s 673ms/step - loss: 4.4660 - bowel_loss: 0.7022 - extra_loss: 0.6549 - liver_loss: 0.9667 - kidney_loss: 1.0919 - spleen_loss: 1.0504 - bowel_accuracy: 0.5036 - extra_accuracy: 0.6646 - liver_accuracy: 0.6403 - kidney_accuracy: 0.3510 - spleen_accuracy: 0.4748 - val_loss: 4.3996 - val_bowel_loss: 0.7070 - val_extra_loss: 0.6766 - val_liver_loss: 0.9773 - val_kidney_loss: 1.0431 - val_spleen_loss: 0.9957 - val_bowel_accuracy: 0.4980 - val_extra_accuracy: 0.5910 - val_liver_accuracy: 0.6397 - val_kidney_accuracy: 0.4661 - val_spleen_accuracy: 0.6032 - lr: 1.0000e-06\n",
      "Epoch 3/3\n",
      "299/299 [==============================] - ETA: 0s - loss: 3.4429 - bowel_loss: 0.6658 - extra_loss: 0.5675 - liver_loss: 0.5572 - kidney_loss: 0.7626 - spleen_loss: 0.8897 - bowel_accuracy: 0.5952 - extra_accuracy: 0.7439 - liver_accuracy: 0.8945 - kidney_accuracy: 0.7525 - spleen_accuracy: 0.6247\n",
      "Epoch 3: val_loss improved from 4.39965 to 3.35942, saving model to fold-0.h5\n",
      "299/299 [==============================] - 211s 705ms/step - loss: 3.4429 - bowel_loss: 0.6658 - extra_loss: 0.5675 - liver_loss: 0.5572 - kidney_loss: 0.7626 - spleen_loss: 0.8897 - bowel_accuracy: 0.5952 - extra_accuracy: 0.7439 - liver_accuracy: 0.8945 - kidney_accuracy: 0.7525 - spleen_accuracy: 0.6247 - val_loss: 3.3594 - val_bowel_loss: 0.6717 - val_extra_loss: 0.6671 - val_liver_loss: 0.7413 - val_kidney_loss: 0.5833 - val_spleen_loss: 0.6961 - val_bowel_accuracy: 0.5751 - val_extra_accuracy: 0.6336 - val_liver_accuracy: 0.7870 - val_kidney_accuracy: 0.8246 - val_spleen_accuracy: 0.7728 - lr: 1.0000e-05\n",
      "FOLD 0 RESULTS\n",
      "BEST Loss  : 3.359\n",
      "BEST Acc   : 0.719\n",
      "BEST Epoch : 2\n",
      "Bowel : 0.575\n",
      "Extravasation : 0.634\n",
      "Liver: 0.787\n",
      "Kidney: 0.825\n",
      "Spleen: 0.773\n",
      "\n",
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "336/336 [==============================] - ETA: 0s - loss: 4.7154 - bowel_loss: 0.6932 - extra_loss: 0.6866 - liver_loss: 1.1135 - kidney_loss: 1.1395 - spleen_loss: 1.0825 - bowel_accuracy: 0.5208 - extra_accuracy: 0.5458 - liver_accuracy: 0.3570 - kidney_accuracy: 0.2981 - spleen_accuracy: 0.4152\n",
      "Epoch 1: val_loss improved from inf to 4.79507, saving model to fold-1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 363s 888ms/step - loss: 4.7154 - bowel_loss: 0.6932 - extra_loss: 0.6866 - liver_loss: 1.1135 - kidney_loss: 1.1395 - spleen_loss: 1.0825 - bowel_accuracy: 0.5208 - extra_accuracy: 0.5458 - liver_accuracy: 0.3570 - kidney_accuracy: 0.2981 - spleen_accuracy: 0.4152 - val_loss: 4.7951 - val_bowel_loss: 0.6988 - val_extra_loss: 0.6981 - val_liver_loss: 1.1181 - val_kidney_loss: 1.1748 - val_spleen_loss: 1.1053 - val_bowel_accuracy: 0.5096 - val_extra_accuracy: 0.5017 - val_liver_accuracy: 0.3304 - val_kidney_accuracy: 0.2350 - val_spleen_accuracy: 0.3575 - lr: 1.0000e-07\n",
      "Epoch 2/3\n",
      "336/336 [==============================] - ETA: 0s - loss: 4.5592 - bowel_loss: 0.6898 - extra_loss: 0.6730 - liver_loss: 1.0541 - kidney_loss: 1.0873 - spleen_loss: 1.0550 - bowel_accuracy: 0.5286 - extra_accuracy: 0.5985 - liver_accuracy: 0.4941 - kidney_accuracy: 0.3989 - spleen_accuracy: 0.4773\n",
      "Epoch 2: val_loss improved from 4.79507 to 4.53124, saving model to fold-1.h5\n",
      "336/336 [==============================] - 240s 711ms/step - loss: 4.5592 - bowel_loss: 0.6898 - extra_loss: 0.6730 - liver_loss: 1.0541 - kidney_loss: 1.0873 - spleen_loss: 1.0550 - bowel_accuracy: 0.5286 - extra_accuracy: 0.5985 - liver_accuracy: 0.4941 - kidney_accuracy: 0.3989 - spleen_accuracy: 0.4773 - val_loss: 4.5312 - val_bowel_loss: 0.6942 - val_extra_loss: 0.6896 - val_liver_loss: 1.0033 - val_kidney_loss: 1.0936 - val_spleen_loss: 1.0506 - val_bowel_accuracy: 0.5096 - val_extra_accuracy: 0.5554 - val_liver_accuracy: 0.6125 - val_kidney_accuracy: 0.3836 - val_spleen_accuracy: 0.5205 - lr: 1.0000e-06\n",
      "Epoch 3/3\n",
      "336/336 [==============================] - ETA: 0s - loss: 3.5036 - bowel_loss: 0.6659 - extra_loss: 0.5769 - liver_loss: 0.6639 - kidney_loss: 0.7394 - spleen_loss: 0.8576 - bowel_accuracy: 0.6005 - extra_accuracy: 0.7275 - liver_accuracy: 0.8497 - kidney_accuracy: 0.7517 - spleen_accuracy: 0.6434\n",
      "Epoch 3: val_loss improved from 4.53124 to 3.31943, saving model to fold-1.h5\n",
      "336/336 [==============================] - 251s 745ms/step - loss: 3.5036 - bowel_loss: 0.6659 - extra_loss: 0.5769 - liver_loss: 0.6639 - kidney_loss: 0.7394 - spleen_loss: 0.8576 - bowel_accuracy: 0.6005 - extra_accuracy: 0.7275 - liver_accuracy: 0.8497 - kidney_accuracy: 0.7517 - spleen_accuracy: 0.6434 - val_loss: 3.3194 - val_bowel_loss: 0.7111 - val_extra_loss: 0.6622 - val_liver_loss: 0.5269 - val_kidney_loss: 0.5465 - val_spleen_loss: 0.8727 - val_bowel_accuracy: 0.5065 - val_extra_accuracy: 0.6404 - val_liver_accuracy: 0.8971 - val_kidney_accuracy: 0.8945 - val_spleen_accuracy: 0.7088 - lr: 1.0000e-05\n",
      "FOLD 1 RESULTS\n",
      "BEST Loss  : 3.319\n",
      "BEST Acc   : 0.729\n",
      "BEST Epoch : 2\n",
      "Bowel : 0.507\n",
      "Extravasation : 0.640\n",
      "Liver: 0.897\n",
      "Kidney: 0.895\n",
      "Spleen: 0.709\n",
      "\n",
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "318/318 [==============================] - ETA: 0s - loss: 4.7363 - bowel_loss: 0.6861 - extra_loss: 0.6781 - liver_loss: 1.1698 - kidney_loss: 1.0585 - spleen_loss: 1.1437 - bowel_accuracy: 0.5421 - extra_accuracy: 0.5721 - liver_accuracy: 0.2412 - kidney_accuracy: 0.4112 - spleen_accuracy: 0.2666\n",
      "Epoch 1: val_loss improved from inf to 4.75584, saving model to fold-2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 398s 1s/step - loss: 4.7363 - bowel_loss: 0.6861 - extra_loss: 0.6781 - liver_loss: 1.1698 - kidney_loss: 1.0585 - spleen_loss: 1.1437 - bowel_accuracy: 0.5421 - extra_accuracy: 0.5721 - liver_accuracy: 0.2412 - kidney_accuracy: 0.4112 - spleen_accuracy: 0.2666 - val_loss: 4.7558 - val_bowel_loss: 0.7057 - val_extra_loss: 0.6664 - val_liver_loss: 1.1814 - val_kidney_loss: 1.0579 - val_spleen_loss: 1.1444 - val_bowel_accuracy: 0.4662 - val_extra_accuracy: 0.6144 - val_liver_accuracy: 0.2047 - val_kidney_accuracy: 0.4101 - val_spleen_accuracy: 0.2506 - lr: 1.0000e-07\n",
      "Epoch 2/3\n",
      "318/318 [==============================] - ETA: 0s - loss: 4.5769 - bowel_loss: 0.6850 - extra_loss: 0.6661 - liver_loss: 1.0973 - kidney_loss: 1.0130 - spleen_loss: 1.1156 - bowel_accuracy: 0.5498 - extra_accuracy: 0.6053 - liver_accuracy: 0.3757 - kidney_accuracy: 0.5069 - spleen_accuracy: 0.3171\n",
      "Epoch 2: val_loss improved from 4.75584 to 4.49217, saving model to fold-2.h5\n",
      "318/318 [==============================] - 242s 758ms/step - loss: 4.5769 - bowel_loss: 0.6850 - extra_loss: 0.6661 - liver_loss: 1.0973 - kidney_loss: 1.0130 - spleen_loss: 1.1156 - bowel_accuracy: 0.5498 - extra_accuracy: 0.6053 - liver_accuracy: 0.3757 - kidney_accuracy: 0.5069 - spleen_accuracy: 0.3171 - val_loss: 4.4922 - val_bowel_loss: 0.7002 - val_extra_loss: 0.6370 - val_liver_loss: 1.0528 - val_kidney_loss: 0.9982 - val_spleen_loss: 1.1040 - val_bowel_accuracy: 0.4932 - val_extra_accuracy: 0.6937 - val_liver_accuracy: 0.4683 - val_kidney_accuracy: 0.5310 - val_spleen_accuracy: 0.3621 - lr: 1.0000e-06\n",
      "Epoch 3/3\n",
      "318/318 [==============================] - ETA: 0s - loss: 3.4440 - bowel_loss: 0.6523 - extra_loss: 0.5896 - liver_loss: 0.6348 - kidney_loss: 0.6758 - spleen_loss: 0.8915 - bowel_accuracy: 0.6141 - extra_accuracy: 0.7043 - liver_accuracy: 0.8511 - kidney_accuracy: 0.8043 - spleen_accuracy: 0.6368\n",
      "Epoch 3: val_loss improved from 4.49217 to 3.59045, saving model to fold-2.h5\n",
      "318/318 [==============================] - 239s 750ms/step - loss: 3.4440 - bowel_loss: 0.6523 - extra_loss: 0.5896 - liver_loss: 0.6348 - kidney_loss: 0.6758 - spleen_loss: 0.8915 - bowel_accuracy: 0.6141 - extra_accuracy: 0.7043 - liver_accuracy: 0.8511 - kidney_accuracy: 0.8043 - spleen_accuracy: 0.6368 - val_loss: 3.5905 - val_bowel_loss: 0.7472 - val_extra_loss: 0.5495 - val_liver_loss: 0.5490 - val_kidney_loss: 0.7793 - val_spleen_loss: 0.9655 - val_bowel_accuracy: 0.4841 - val_extra_accuracy: 0.7652 - val_liver_accuracy: 0.8328 - val_kidney_accuracy: 0.7487 - val_spleen_accuracy: 0.6179 - lr: 1.0000e-05\n",
      "FOLD 2 RESULTS\n",
      "BEST Loss  : 3.590\n",
      "BEST Acc   : 0.690\n",
      "BEST Epoch : 2\n",
      "Bowel : 0.484\n",
      "Extravasation : 0.765\n",
      "Liver: 0.833\n",
      "Kidney: 0.749\n",
      "Spleen: 0.618\n",
      "\n",
      ">>>> Load pretrained from: /Users/makoto/.keras/models/efficientnetv2-b0-imagenet.h5\n",
      "Epoch 1/3\n",
      "269/269 [==============================] - ETA: 0s - loss: 4.6534 - bowel_loss: 0.7006 - extra_loss: 0.7241 - liver_loss: 1.0110 - kidney_loss: 1.0969 - spleen_loss: 1.1208 - bowel_accuracy: 0.4911 - extra_accuracy: 0.4235 - liver_accuracy: 0.5194 - kidney_accuracy: 0.3742 - spleen_accuracy: 0.3007\n",
      "Epoch 1: val_loss improved from inf to 4.61094, saving model to fold-3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makoto/homebrew/Caskroom/miniforge/base/envs/rsna2023/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 379s 1s/step - loss: 4.6534 - bowel_loss: 0.7006 - extra_loss: 0.7241 - liver_loss: 1.0110 - kidney_loss: 1.0969 - spleen_loss: 1.1208 - bowel_accuracy: 0.4911 - extra_accuracy: 0.4235 - liver_accuracy: 0.5194 - kidney_accuracy: 0.3742 - spleen_accuracy: 0.3007 - val_loss: 4.6109 - val_bowel_loss: 0.6989 - val_extra_loss: 0.7200 - val_liver_loss: 0.9785 - val_kidney_loss: 1.1111 - val_spleen_loss: 1.1024 - val_bowel_accuracy: 0.5018 - val_extra_accuracy: 0.4482 - val_liver_accuracy: 0.5876 - val_kidney_accuracy: 0.3397 - val_spleen_accuracy: 0.3450 - lr: 1.0000e-07\n",
      "Epoch 2/3\n",
      "269/269 [==============================] - ETA: 0s - loss: 4.5335 - bowel_loss: 0.7002 - extra_loss: 0.7152 - liver_loss: 0.9664 - kidney_loss: 1.0569 - spleen_loss: 1.0949 - bowel_accuracy: 0.4947 - extra_accuracy: 0.4459 - liver_accuracy: 0.6117 - kidney_accuracy: 0.4654 - spleen_accuracy: 0.3480\n",
      "Epoch 2: val_loss improved from 4.61094 to 4.39528, saving model to fold-3.h5\n",
      "269/269 [==============================] - 225s 834ms/step - loss: 4.5335 - bowel_loss: 0.7002 - extra_loss: 0.7152 - liver_loss: 0.9664 - kidney_loss: 1.0569 - spleen_loss: 1.0949 - bowel_accuracy: 0.4947 - extra_accuracy: 0.4459 - liver_accuracy: 0.6117 - kidney_accuracy: 0.4654 - spleen_accuracy: 0.3480 - val_loss: 4.3953 - val_bowel_loss: 0.6997 - val_extra_loss: 0.6974 - val_liver_loss: 0.8956 - val_kidney_loss: 1.0320 - val_spleen_loss: 1.0706 - val_bowel_accuracy: 0.4950 - val_extra_accuracy: 0.5088 - val_liver_accuracy: 0.7494 - val_kidney_accuracy: 0.5188 - val_spleen_accuracy: 0.4004 - lr: 1.0000e-06\n",
      "Epoch 3/3\n",
      "269/269 [==============================] - ETA: 0s - loss: 3.5426 - bowel_loss: 0.6677 - extra_loss: 0.6319 - liver_loss: 0.6561 - kidney_loss: 0.7214 - spleen_loss: 0.8655 - bowel_accuracy: 0.5856 - extra_accuracy: 0.6450 - liver_accuracy: 0.8210 - kidney_accuracy: 0.7753 - spleen_accuracy: 0.6634\n",
      "Epoch 3: val_loss improved from 4.39528 to 3.32853, saving model to fold-3.h5\n",
      "269/269 [==============================] - 233s 866ms/step - loss: 3.5426 - bowel_loss: 0.6677 - extra_loss: 0.6319 - liver_loss: 0.6561 - kidney_loss: 0.7214 - spleen_loss: 0.8655 - bowel_accuracy: 0.5856 - extra_accuracy: 0.6450 - liver_accuracy: 0.8210 - kidney_accuracy: 0.7753 - spleen_accuracy: 0.6634 - val_loss: 3.3285 - val_bowel_loss: 0.6761 - val_extra_loss: 0.5672 - val_liver_loss: 0.3792 - val_kidney_loss: 0.7451 - val_spleen_loss: 0.9610 - val_bowel_accuracy: 0.5677 - val_extra_accuracy: 0.7596 - val_liver_accuracy: 0.9660 - val_kidney_accuracy: 0.7911 - val_spleen_accuracy: 0.5799 - lr: 1.0000e-05\n",
      "FOLD 3 RESULTS\n",
      "BEST Loss  : 3.329\n",
      "BEST Acc   : 0.733\n",
      "BEST Epoch : 2\n",
      "Bowel : 0.568\n",
      "Extravasation : 0.760\n",
      "Liver: 0.966\n",
      "Kidney: 0.791\n",
      "Spleen: 0.580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold in np.arange(CFG.folds):\n",
    "\n",
    "    train_df = df.query(\"fold!=@fold\")\n",
    "    valid_df = df.query(\"fold==@fold\")\n",
    "\n",
    "    train_paths  = train_df.image_path.values\n",
    "    train_labels = train_df[CFG.target_col].values.astype(np.float32)\n",
    "    valid_paths  = valid_df.image_path.values\n",
    "    valid_labels = valid_df[CFG.target_col].values.astype(np.float32)\n",
    "    test_paths   = test_df.image_path.values\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = build_model(CFG.model_name, dim=CFG.img_size)\n",
    "\n",
    "    train_ds = build_dataset(train_paths, train_labels)\n",
    "    valid_ds = build_dataset(valid_paths, valid_labels)\n",
    "\n",
    "    callbacks = []\n",
    "    ## save best model after each fold\n",
    "    save = tf.keras.callbacks.ModelCheckpoint('fold-%i.h5'%fold, monitor='val_loss', \n",
    "                                              verbose=1, save_best_only=True,\n",
    "                                              save_weights_only=False, mode='min', save_freq='epoch')\n",
    "    callbacks +=[save]\n",
    "    callbacks += [get_lr_callback(CFG.batch_size)]\n",
    "\n",
    "\n",
    "    history = model.fit(train_ds, validation_data = valid_ds, \n",
    "                        epochs=CFG.epochs, steps_per_epoch=None, \n",
    "                        callbacks = callbacks, verbose=1)\n",
    "                        \n",
    "    best_epoch = np.argmin(history.history['val_loss'])\n",
    "    best_loss = history.history['val_loss'][best_epoch]\n",
    "    best_acc_bowel = history.history['val_bowel_accuracy'][best_epoch]\n",
    "    best_acc_extra = history.history['val_extra_accuracy'][best_epoch]\n",
    "    best_acc_liver = history.history['val_liver_accuracy'][best_epoch]\n",
    "    best_acc_kidney = history.history['val_kidney_accuracy'][best_epoch]\n",
    "    best_acc_spleen = history.history['val_spleen_accuracy'][best_epoch]\n",
    "\n",
    "    best_acc = np.mean([best_acc_bowel, best_acc_extra, best_acc_liver, best_acc_kidney, best_acc_spleen])\n",
    "    print(f'FOLD {fold} RESULTS')\n",
    "    print(f'BEST Loss  : {best_loss:.3f}\\nBEST Acc   : {best_acc:.3f}\\nBEST Epoch : {best_epoch}')\n",
    "    print(f'Bowel : {best_acc_bowel:.3f}')\n",
    "    print(f'Extravasation : {best_acc_extra:.3f}')\n",
    "    print(f'Liver: {best_acc_liver:.3f}')\n",
    "    print(f'Kidney: {best_acc_kidney:.3f}')\n",
    "    print(f'Spleen: {best_acc_spleen:.3f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_proc(pred):\n",
    "    argmax = np.argmax(pred, axis=1).astype('uint8')\n",
    "    one_hot = tf.keras.utils.to_categorical(argmax, num_classes=3)\n",
    "    return one_hot.astype('uint8')\n",
    "\n",
    "def sc_proc(pred, thr=0.5):\n",
    "    proc_pred = (pred > thr).astype('uint8')\n",
    "    return proc_pred\n",
    "\n",
    "def post_proc(pred):\n",
    "    proc_pred = np.empty((pred.shape[0], 2*2 + 3*3), dtype='float32')\n",
    "\n",
    "    proc_pred[:, 0] = 1 - pred[:, 0] # bowel-healthy\n",
    "    proc_pred[:, 1] = pred[:, 0] # bowel-injured\n",
    "    proc_pred[:, 2] = 1 - pred[:, 1] # extra-healthy\n",
    "    proc_pred[:, 3] = pred[:, 1] # extra-injured\n",
    "    \n",
    "    proc_pred[:, 4:7] = pred[:, 2:5] # liver\n",
    "    proc_pred[:, 7:10] = pred[:, 5:8] # kidney\n",
    "    proc_pred[:, 10:13] = pred[:, 8:11] # spleen\n",
    "\n",
    "    return proc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[512, 512], ['./fold-0.h5', './fold-1.h5', './fold-2.h5', './fold-3.h5']]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPT_DIRS = [\n",
    "    ([512, 512], './'),\n",
    "]\n",
    "\n",
    "MODEL_CONFIGS = []\n",
    "for img_size, ckpt_dir in  CKPT_DIRS:\n",
    "    paths = sorted(glob(os.path.join(ckpt_dir, '*h5')))[0:CFG.folds]\n",
    "    if len(paths)==0:\n",
    "        print('no model found for :',base_dir)\n",
    "    MODEL_CONFIGS.append([img_size, paths])\n",
    "display(MODEL_CONFIGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 48843\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 14s 14s/step\n",
      "1/1 [==============================] - 15s 15s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:05, 65.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 50046\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 15s 15s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:11, 65.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 63706\n",
      "1/1 [==============================] - 16s 16s/step\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 16s 16s/step\n",
      "1/1 [==============================] - 16s 16s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:21, 67.06s/it]\n"
     ]
    }
   ],
   "source": [
    "patient_ids = test_df['patient_id'].unique()\n",
    "\n",
    "patient_ids.sort()\n",
    "\n",
    "patient_preds = np.zeros(shape=(len(patient_ids), 2*2 + 3*3), dtype='float32')\n",
    "\n",
    "preds = np.zeros(shape=(1, 11), dtype=np.float32)\n",
    "\n",
    "for pidx, patient_id in tqdm(enumerate(patient_ids)):\n",
    "\n",
    "    patient_df = test_df[test_df['patient_id'] != patient_id]\n",
    "\n",
    "    model_preds = np.zeros(shape=(1, 11), dtype=np.float32)\n",
    "\n",
    "    print(f'Patient ID: {patient_id}')\n",
    "\n",
    "    for midx, (img_size, fold_paths) in enumerate(MODEL_CONFIGS):\n",
    "\n",
    "        patient_paths = patient_df.image_path.tolist()\n",
    "\n",
    "        min_batchsize = len(patient_paths)\n",
    "        CFG.batch_size = min(min_batchsize, CFG.batch_size)\n",
    "\n",
    "        dtest = build_dataset(patient_paths, batch_size=CFG.batch_size, repeat=False, \n",
    "                             shuffle=False, augment=False, cache=False,\n",
    "                             decode_fn=build_decoder(with_labels=False, target_size=CFG.img_size),)\n",
    "        \n",
    "        for fold_path in fold_paths:\n",
    "            \n",
    "            model = tf.keras.models.load_model(fold_path, compile=False)\n",
    "             \n",
    "            pred = model.predict(dtest, verbose=1)\n",
    "            pred = np.concatenate(pred, axis=-1).astype('float32')\n",
    "            pred = pred[:len(patient_paths), :]\n",
    "            pred = np.mean(pred.reshape(1, len(patient_paths), 11), axis=0)\n",
    "            pred = np.max(pred, axis=0) # taking max prediction of all ct scans for a patient\n",
    "\n",
    "            model_preds += pred / (len(fold_paths)*len(MODEL_CONFIGS))\n",
    "                                   \n",
    "            del model, pred; gc.collect()\n",
    "        \n",
    "        del dtest, patient_paths; gc.collect()\n",
    "\n",
    "        patient_preds[pidx, :] += post_proc(model_preds)[0]\n",
    "\n",
    "    del model_preds; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40062475, 0.59937525, 0.22364593, 0.7763541 , 0.9151776 ,\n",
       "        0.15811184, 0.13074802, 0.82899284, 0.23013932, 0.15492648,\n",
       "        0.665516  , 0.21227756, 0.29290068],\n",
       "       [0.37804663, 0.62195337, 0.27994287, 0.72005713, 0.812729  ,\n",
       "        0.15811184, 0.13626885, 0.64639366, 0.2462556 , 0.16300628,\n",
       "        0.5986967 , 0.23405993, 0.29851973],\n",
       "       [0.3460881 , 0.6539119 , 0.21036804, 0.78963196, 0.9151776 ,\n",
       "        0.07496762, 0.11230343, 0.82899284, 0.23245439, 0.13489307,\n",
       "        0.665516  , 0.20801646, 0.2221129 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Dataset/test_images/50046/24574/30.png</td>\n",
       "      <td>50046</td>\n",
       "      <td>24574</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Dataset/test_images/63706/39279/30.png</td>\n",
       "      <td>63706</td>\n",
       "      <td>39279</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Dataset/test_images/48843/62825/30.png</td>\n",
       "      <td>48843</td>\n",
       "      <td>62825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_path  patient_id  series_id  \\\n",
       "0  ./Dataset/test_images/50046/24574/30.png       50046      24574   \n",
       "1  ./Dataset/test_images/63706/39279/30.png       63706      39279   \n",
       "2  ./Dataset/test_images/48843/62825/30.png       48843      62825   \n",
       "\n",
       "   instance_number  \n",
       "0               30  \n",
       "1               30  \n",
       "2               30  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'patient_id':patient_ids,})\n",
    "\n",
    "sub_df = pd.read_csv('./sample_submission.csv')\n",
    "pred_df = pred_df.merge(sub_df, on='patient_id', how='right')\n",
    "\n",
    "for i, row in enumerate(patient_preds):\n",
    "    pred_df.loc[i, 'bowel_healthy'] = row[0]\n",
    "    pred_df.loc[i, 'bowel_injury'] = row[1]\n",
    "    pred_df.loc[i, 'extravasation_healthy'] = row[2]\n",
    "    pred_df.loc[i, 'extravasation_injury'] = row[3]\n",
    "    pred_df.loc[i, 'kidney_healthy'] = row[4]\n",
    "    pred_df.loc[i, 'kidney_low'] = row[5]\n",
    "    pred_df.loc[i, 'kidney_high'] = row[6]\n",
    "    pred_df.loc[i, 'liver_healthy'] = row[7]\n",
    "    pred_df.loc[i, 'liver_low'] = row[8]\n",
    "    pred_df.loc[i, 'liver_high'] = row[9]\n",
    "    pred_df.loc[i, 'spleen_healthy'] = row[10]\n",
    "    pred_df.loc[i, 'spleen_low'] = row[11]\n",
    "    pred_df.loc[i, 'spleen_high'] = row[12]\n",
    "\n",
    "pred_df.to_csv('submission01.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsna2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
